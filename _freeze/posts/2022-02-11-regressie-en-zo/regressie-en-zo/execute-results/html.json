{
  "hash": "f213ba2c73d47c92dcda04c83e0e8144",
  "result": {
    "markdown": "---\ntitle: \"Regressie en nog zo iets\"\ndescription: |\n     Dit is een blog naar aanleiding van Gelman/Hill/Vehtari nieuwe boek Regresion and other stories\nauthor: \"Harrie Jonkman\"\ndate: \"2022-02-10\"\ncategories: [analyse]\nimage: \"Screenshot.png\"\n---\n\n\n## Regression and other stories\nVijftien jaar geleden schreven Gelman en Hill **Data analysis using regression and multilevel/hierarchical models**, een klassieker over moderne data-analyse. Ze gebruikte R en WinBugs voor lineaire en logistische, hierarchische regressieanalyse en causale inferentie. Ze lieten zien hoe je dat op de frequentistische en Bayesiaanse manier kunt doen. Het boek werd voor mij een naslagwerk dat ik steeds maar weer uit de kast trok. Vorig jaar  dacht ik, laat ik eens zien of Gelman al weer iets nieuws heeft geschreven en toen zag ik dat **Regression and other stories** [hier](https://www.cambridge.org/fi/academic/subjects/statistics-probability/statistical-theory-and-methods/regression-and-other-stories)net uit was is. Dat heeft Andrew Gelman weer met Jennifer Hill geschreven maar nu ook met de Fin Aki Vehtari. Ik was er nog niet aan toe gekomen om het te lezen. Dat heb ik deze maand gedaan. Ook dit boek zal ik vaker uit de kast trekken. Dit boek gaat over allerlei aspecten van regressie. Het is een theoretisch én praktisch boek. Je leert, wat ze noemen, voorspellende modellen beter begrijpen, toepassen in verschillende praktische problemen en je leert het simuleren. Je leert het opbouwen vanaf de basis en daarna kun je het in verschillende situaties toepassen. Het wil kritisch zijn, zonder nihilistisch te worden en vooral laten zien dat je van statistische analyse kunt leren. Ook dit boek staat op twee benen: frequentisch en Bayesiaans en laat zien hoe informatie wordt gebruikt in het schattingsproces, de assumpties die eraan ten grondslag liggen en hoe schattingen en voorspellingen kunnen worden geïnterpreteerd in beide raamwerken. Beide kunnen worden gebruikt, maar het is ook duidelijk dat de voorkeur bij Bayesiaanse benadering ligt. Dan kun je ook andere informatie gebruiken om te schatten of te voorspellen. En omdat je simuleert (het model duizenden keren draait) kunt je met de Bayesiaanse techniek meer zeggen over onzekerheid. Dat maakt deze techniek zeer geschikt voor regressieanalyses zoals in dit boek gepresenteerd. \nWat ik zelf van dit boek heb geleerd zijn de mogelijkheden om op basis van gegevens te voorspellen. Vooral hoofdstuk 9 (Voorspellen en Bayesiaanse inferentie) vond ik interessant. Maar het boek zit vol informatie en kennis en laat zich amper samenvatten. Het lijkt erop dat het een eerste deel is en ik verwacht dat er later nog een tweede deel komt dat de nadruk legt op multilevel analyse. We zullen zien Bij het boek zit ook nog een website met data en scripts om zelf uit te proberen, prachtig onderwijsmateriaal opgesteld door Aki Vehtari [hier](https://avehtari.github.io/ROS-Examples/). \n\n## Interssante blog\nToen ik het boek uit had kwam ik een een blog tegen op R-bloggers. Het verscheen op 1 september 2021  [hier](https://www.r-bloggers.com/2021/09/bayesian-regression-analysis-with-rstanarm/#google_vignette), maar ik kon niet zien van wie het is (Mister X, sorry. Hij of zij schreef het nadat deze persoon **Regression and other stories** had gelezen. Het vat heel goed samen hoe moderne regressieanalyse werkt en daarom heb ik het voor hier vertaald. \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Eerst de pakketten inladen die we nodig hebben\nlibrary(plyr); library(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'plyr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'dplyr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'dplyr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:plyr':\n\n    arrange, count, desc, failwith, id, mutate, rename, summarise,\n    summarize\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n:::\n\n```{.r .cell-code}\nlibrary(rstanarm)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'rstanarm' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: Rcpp\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'Rcpp' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is rstanarm version 2.21.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- Default priors may change, so it's safest to specify priors, even if equivalent to the defaults.\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- For execution on a local, multicore CPU with excess RAM we recommend calling\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n  options(mc.cores = parallel::detectCores())\n```\n:::\n\n```{.r .cell-code}\nlibrary(bayesplot)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'bayesplot' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThis is bayesplot version 1.9.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- Online documentation and vignettes at mc-stan.org/bayesplot\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n- bayesplot theme set to bayesplot::theme_default()\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n   * Does _not_ affect other ggplot2 plots\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n   * See ?bayesplot_theme_set for details on theme setting\n```\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.1.3\n```\n:::\n\n```{.r .cell-code}\nlibrary(readr)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'readr' was built under R version 4.1.3\n```\n:::\n:::\n\n\n## Bayesiaanse regressieanalyse met Rstanarm\n\nIn deze post zullen we een eenvoudig voorbeeld van Bayesiaanse regressieanalyse doornemen met het rstanarm pakket in R. Ik heb Gelman, Hill en Vehtari's recente boek *Regression and Other Stories\" gelezen*, en deze blog post is mijn poging om enkele van de dingen die ik heb geleerd toe te passen. Ik heb de afgelopen jaren stukjes en beetjes van de Bayesiaanse benadering opgevangen, en ik vind het een heel interessante manier om over gegevensanalyse na te denken en ze uit te voeren. Ik heb met veel plezier het nieuwe boek van Gelman en collega's doorgewerkt en geëxperimenteerd met deze technieken, en ik ben blij dat ik hier iets kan delen van wat ik heb geleerd.\n\nJe kunt de gegevens en alle code van deze blogpost [hier]() op Github vinden.\n\n\n## De data\nDe gegevens die we in deze blog zullen onderzoeken bestaan uit de dagelijkse totale stappentellingen van verschillende fitnesstrackers die ik de afgelopen 6 jaar heb gehad. De eerste waarneming werd geregistreerd op 2015-03-04 en de laatste op 2021-03-15. Gedurende deze periode bevat de dataset de dagelijkse totale stappentellingen voor 2.181 dagen.\n\nNaast de dagelijkse totale stappentelling bevat de dataset informatie over de dag van de week (bijv. maandag, dinsdag, etc.), het apparaat dat is gebruikt om de stappentelling vast te leggen (door de jaren heen heb ik er 3 gehad - Accupedo, Fitbit en Mi-Band), en het weer voor elke datum (de gemiddelde dagelijkse temperatuur in graden Celsius en de totale dagelijkse neerslag in millimeters, verkregen via het GSODR pakket in R).\n\nDe dataset (genaamd steps_weather) ziet er als volgt uit:   \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Data inladen\nlibrary(readr)\nsteps_weather <- read_csv(\"C:/FilesHarrie/Stanexample/Rstanarmexample/bayesian_regression_rstanarm/Data/steps_weather.csv\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 2181 Columns: 7\n-- Column specification --------------------------------------------------------\nDelimiter: \",\"\nchr  (3): dow, week_weekend, device\ndbl  (3): daily_total, temp, prcp\ndate (1): date\n\ni Use `spec()` to retrieve the full column specification for this data.\ni Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\nhead(steps_weather)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 7\n  date       daily_total dow   week_weekend device    temp  prcp\n  <date>           <dbl> <chr> <chr>        <chr>    <dbl> <dbl>\n1 2015-03-04       14136 Wed   Weekday      Accupedo   4.3   1.3\n2 2015-03-05       11248 Thu   Weekday      Accupedo   4.7   0  \n3 2015-03-06       12803 Fri   Weekday      Accupedo   5.4   0  \n4 2015-03-07       15011 Sat   Weekend      Accupedo   7.9   0  \n5 2015-03-08        9222 Sun   Weekend      Accupedo  10.2   0  \n6 2015-03-09       21452 Mon   Weekday      Accupedo   8.8   0  \n```\n:::\n:::\n\n\nHieronder zie je de eerste en laatste data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmin(steps_weather$date)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2015-03-04\"\n```\n:::\n\n```{.r .cell-code}\nmax(steps_weather$date)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"2021-03-15\"\n```\n:::\n:::\n\nHieronder zie je histogrammen van twee variabelen, namelijk dagelijks totale aantal stappen en de gemiddelde temperatuur over deze periode. \n\n::: {.cell}\n\n```{.r .cell-code}\nhist(steps_weather$daily_total, breaks = 50)\n```\n\n::: {.cell-output-display}\n![](regressie-en-zo_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n\n```{.r .cell-code}\nhist(steps_weather$temp, breaks = 50)\n```\n\n::: {.cell-output-display}\n![](regressie-en-zo_files/figure-html/unnamed-chunk-4-2.png){width=672}\n:::\n:::\n\n\n## Regressie Analyse\nHet doel van deze blogbijdrage is Bayesiaanse regressiemodellering te verkennen met behulp van het *rstanarm* pakket. Daarom zullen we de gegevens gebruiken om een zeer eenvoudig model te maken en ons te concentreren op het begrijpen van de modelfit en verschillende regressiediagnoses.\n\nOns model hier is een lineair regressiemodel dat de gemiddelde temperatuur in graden Celsius gebruikt om het totale dagelijkse aantal stappen te voorspellen. We gebruiken het *stan_glm* commando om de regressie-analyse uit te voeren. We kunnen het model uitvoeren en een samenvatting van de resultaten zien die de volgende tabel oplevert.\n\nHet draait 4.000 iteraties en daarna worden de resultaten gepresenteerd.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_1 <- stan_glm(daily_total ~ temp, data = steps_weather) \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 1).\nChain 1: \nChain 1: Gradient evaluation took 0 seconds\nChain 1: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\nChain 1: Adjust your expectations accordingly!\nChain 1: \nChain 1: \nChain 1: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 1: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 1: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 1: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 1: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 1: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 1: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 1: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 1: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 1: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 1: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 1: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 1: \nChain 1:  Elapsed Time: 0.473 seconds (Warm-up)\nChain 1:                0.184 seconds (Sampling)\nChain 1:                0.657 seconds (Total)\nChain 1: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 2).\nChain 2: \nChain 2: Gradient evaluation took 0 seconds\nChain 2: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\nChain 2: Adjust your expectations accordingly!\nChain 2: \nChain 2: \nChain 2: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 2: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 2: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 2: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 2: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 2: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 2: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 2: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 2: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 2: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 2: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 2: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 2: \nChain 2:  Elapsed Time: 0.277 seconds (Warm-up)\nChain 2:                0.174 seconds (Sampling)\nChain 2:                0.451 seconds (Total)\nChain 2: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 3).\nChain 3: \nChain 3: Gradient evaluation took 0 seconds\nChain 3: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\nChain 3: Adjust your expectations accordingly!\nChain 3: \nChain 3: \nChain 3: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 3: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 3: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 3: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 3: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 3: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 3: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 3: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 3: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 3: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 3: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 3: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 3: \nChain 3:  Elapsed Time: 0.584 seconds (Warm-up)\nChain 3:                0.168 seconds (Sampling)\nChain 3:                0.752 seconds (Total)\nChain 3: \n\nSAMPLING FOR MODEL 'continuous' NOW (CHAIN 4).\nChain 4: \nChain 4: Gradient evaluation took 0 seconds\nChain 4: 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.\nChain 4: Adjust your expectations accordingly!\nChain 4: \nChain 4: \nChain 4: Iteration:    1 / 2000 [  0%]  (Warmup)\nChain 4: Iteration:  200 / 2000 [ 10%]  (Warmup)\nChain 4: Iteration:  400 / 2000 [ 20%]  (Warmup)\nChain 4: Iteration:  600 / 2000 [ 30%]  (Warmup)\nChain 4: Iteration:  800 / 2000 [ 40%]  (Warmup)\nChain 4: Iteration: 1000 / 2000 [ 50%]  (Warmup)\nChain 4: Iteration: 1001 / 2000 [ 50%]  (Sampling)\nChain 4: Iteration: 1200 / 2000 [ 60%]  (Sampling)\nChain 4: Iteration: 1400 / 2000 [ 70%]  (Sampling)\nChain 4: Iteration: 1600 / 2000 [ 80%]  (Sampling)\nChain 4: Iteration: 1800 / 2000 [ 90%]  (Sampling)\nChain 4: Iteration: 2000 / 2000 [100%]  (Sampling)\nChain 4: \nChain 4:  Elapsed Time: 0.884 seconds (Warm-up)\nChain 4:                0.174 seconds (Sampling)\nChain 4:                1.058 seconds (Total)\nChain 4: \n```\n:::\n\n```{.r .cell-code}\nsummary(fit_1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nModel Info:\n function:     stan_glm\n family:       gaussian [identity]\n formula:      daily_total ~ temp\n algorithm:    sampling\n sample:       4000 (posterior sample size)\n priors:       see help('prior_summary')\n observations: 2181\n predictors:   2\n\nEstimates:\n              mean    sd      10%     50%     90%  \n(Intercept) 16218.9   276.0 15869.3 16215.8 16580.9\ntemp           26.6    21.0    -0.9    26.4    53.5\nsigma        6199.8    96.4  6082.2  6198.2  6322.6\n\nFit Diagnostics:\n           mean    sd      10%     50%     90%  \nmean_PPD 16519.2   190.8 16279.1 16518.9 16767.0\n\nThe mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help('summary.stanreg')).\n\nMCMC diagnostics\n              mcse Rhat n_eff\n(Intercept)   4.3  1.0  4169 \ntemp          0.3  1.0  4436 \nsigma         1.7  1.0  3317 \nmean_PPD      3.1  1.0  3896 \nlog-posterior 0.0  1.0  1716 \n\nFor each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1).\n```\n:::\n:::\n\nDeze tabel bevat de volgende variabelen:\n\n- **Intercept**: Dit cijfer geeft het verwachte dagelijkse aantal stappen weer wanneer de gemiddelde dagtemperatuur 0 is. Met andere woorden, het model voorspelt dat, wanneer de gemiddelde dagtemperatuur 0 graden Celsius is, ik op die dag 16211,7 stappen zal lopen.\n- **temp**: Dit is de geschatte toename van het dagelijkse aantal stappen per 1 eenheid stijging van de gemiddelde dagelijkse temperatuur in graden Celsius. Met andere woorden, het model voorspelt dat voor elke 1 graad stijging van de gemiddelde dagtemperatuur, ik die dag 26,8 extra stappen zal zetten.\n- **sigma**: Dit is de geschatte standaardafwijking van de residuen van het regressiemodel. (Het residu is het verschil tussen de modelvoorspelling en de waargenomen waarde voor het dagelijkse totale aantal stappen). De verdeling van de residuele waarden heeft een standaardafwijking van 6195,1.\n- **geman_PPD**: De mean_ppd is de gemiddelde posterior predictive distributie van de door het model geïmpliceerde uitkomstvariabele (we zullen dit verder bespreken in het gedeelte over posterior predictive checques hieronder).\n\nDe uitvoer in de samenvattende tabel hierboven lijkt vrij veel op de uitvoer van een standaard gewone kleinste kwadratenregressie. In de Bayesiaanse benadering van regressiemodellering krijgen we echter niet gewoon puntschattingen van coëfficiënten, maar eerder volledige verdelingen van simulaties die mogelijke waarden van de coëfficiënten vertegenwoordigen, gegeven het model. Met andere woorden, de getallen in de bovenstaande tabel zijn gewoon samenvattingen van verdelingen van coëfficiënten die de relatie tussen de voorspellers en de uitkomstvariabele beschrijven.\n\nStandaard geven de **rstanarm** regressiemodellen 4.000 simulaties van de posterior verdeling voor elke modelparameter. We kunnen de simulaties uit het modelobject halen en ze als volgt bekijken:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# extraheer de simulaties van het modelobject\nsims <- as.matrix(fit_1)\n```\n:::\n\n\nEn dat geeft 4000 posterior simulaties van de parameters intercept, temp en sd. Deze simulaties drukken de onzekerheid uit van de modeloutput die je hierboven vindt\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(sims)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          parameters\niterations (Intercept)      temp    sigma\n      [1,]    16172.03 34.679624 6116.416\n      [2,]    16380.96 22.963727 6173.921\n      [3,]    16054.89 29.856779 6223.247\n      [4,]    16107.86 28.293847 6290.878\n      [5,]    16487.89 18.927277 6172.173\n      [6,]    16692.51  6.882619 6199.710\n```\n:::\n:::\n\n\nDe gemiddelde waarden van deze verdelingen van simulaties worden weergegeven in de hierboven afgebeelde tabel met regressiesamenvattingsuitvoer.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gemiddelde en intercept - matchen met de tabel \nmean(sims[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 16218.87\n```\n:::\n\n```{.r .cell-code}\nsd(sims[,1])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 275.9854\n```\n:::\n\n```{.r .cell-code}\n# gemiddelde en sd temp - matchen met de tabel \nmean(sims[,2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 26.62242\n```\n:::\n\n```{.r .cell-code}\nmedian(sims[,2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 26.44791\n```\n:::\n\n```{.r .cell-code}\nsd(sims[,2])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 21.03643\n```\n:::\n\n```{.r .cell-code}\n# gemiddelde en sd sigma - matchen met de tabel \nmean(sims[,3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 6199.79\n```\n:::\n\n```{.r .cell-code}\nsd(sims[,3])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 96.39904\n```\n:::\n:::\n\n\n## Visualiseren van de posterior distributies met bayesplot\nHet uitstekende **bayesplot**-pakket bevat een aantal handige functies om de posterior distributies van onze coëfficiënten te visualiseren. Laten we de mcmc_areas-functie gebruiken om de 90% geloofwaardige intervallen voor de modelcoëfficiënten weer te geven. die de volgende plot oplevert.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncolor_scheme_set(\"red\")\nplot_title <- ggtitle(\"Posterior distributies\",\n                      \"met medianen en 90% intervallen\")\nmcmc_areas(sims, prob = 0.90) + plot_title\n```\n\n::: {.cell-output-display}\n![](regressie-en-zo_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nDeze grafiek is zeer interessant en toont ons de posterior distributie van de simulaties van het model dat we hierboven hebben getoond. De plot geeft ons een idee van de variatie van alle parameters, maar de coëfficiënten liggen op zulke verschillende schalen dat de details verloren gaan door ze allemaal samen weer te geven.\n\nLaten we ons concentreren op de temperatuurcoëfficiënt en een gebiedsplot maken met alleen deze parameter:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# area plot van temperatuur parameter\nmcmc_areas(sims,\n          pars = c(\"temp\"),\n          prob = 0.90) + plot_title\n```\n\n::: {.cell-output-display}\n![](regressie-en-zo_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\nDeze grafiek toont de mediaan van de verdeling (26,69, die zeer dicht bij ons gemiddelde van 26,83 ligt). We kunnen de grenzen van het hierboven getoonde gearceerde gebied bepalen met de posterior_interval functie, of rechtstreeks uit de simulaties zelf:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nposterior_interval(fit_1, pars = \"temp\", prob=.9)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n           5%      95%\ntemp -8.21517 60.75168\n```\n:::\n\n```{.r .cell-code}\n# of rechtstreeks van de posterior distribution\nquantile(sims[,2], probs = c(.05,.95))  \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      5%      95% \n-8.21517 60.75168 \n```\n:::\n:::\n\n\nBeide methoden geven hetzelfde resultaat.\n\n## Visualiseren van slopes van de posterior distributie \nEen andere interessante manier om de verschillende coëfficiënten uit de posterior verdeling te visualiseren is door de regressielijnen van vele simulaties uit de posterior distributie gelijktijdig uit te zetten tegen de ruwe data. Deze visualisatietechniek wordt veel gebruikt in zowel Richard McElreath's *Statistical Rethinking* als in Gelmans *Regression and Other Stories*. Beide boeken maken dit soort tekeningen met behulp van plotfuncties in basis-R. Ik was erg blij deze blog post te vinden met een voorbeeld van hoe je deze plots kan maken met behulp van *ggplot2*! Ik heb de code lichtjes aangepast om de onderstaande figuur te maken.\n\nDe eerste stap is het extraheren van de basisinformatie om elke regressielijn te tekenen. We doen dit met de volgende code, waarbij we in essentie ons model-object doorgeven aan een dataframe, en dan enkel het intercept en de temperatuur-hellingen voor elk van onze 4.000 simulaties uit de posterior distributie houden.\n\nDit geeft het volgende dataframe terug:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Dit is een data-frame van posterior samples \n# Een rij per sample.\nfits <- fit_1 %>% \n  as_tibble() %>% \n  rename(intercept = `(Intercept)`) %>% \n  select(-sigma)\n# hoe ziet dat dataframe eruit?\nhead(fits)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 2\n  intercept  temp\n      <dbl> <dbl>\n1    16172. 34.7 \n2    16381. 23.0 \n3    16055. 29.9 \n4    16108. 28.3 \n5    16488. 18.9 \n6    16693.  6.88\n```\n:::\n:::\n\n\nDit dataframe heeft 4.000 rijen, één voor elke simulatie uit de posterior verdeling in onze originele sims matrix.\n\nWe stellen dan enkele \"esthetische regelaars\" in, die specificeren hoeveel lijnen van de posterior verdeling we willen plotten, hun transparantie (de *alpha* parameter), en de kleuren voor de individuele posterior lijnen en het algemene gemiddelde van de posterior schattingen. De ggplot2 code stelt dan de assen in met het originele data frame (steps_weather), plot een steekproef van regressielijnen uit de posterior verdeling in licht grijs, en plot dan de gemiddelde helling van alle posterior simulaties in blauw.\n\n\nDat levert de volgende plot op:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Eerst de opmaak instellen\nn_draws <- 500\nalpha_level <- .15\ncolor_draw <- \"grey60\"\ncolor_mean <-  \"#3366FF\"\n\n# plot maken\nggplot(steps_weather) + \n  # eerst - eerst de assen van de originele data bepalen\n  aes(x = temp, y = daily_total ) + \n  # restrictie opleggen aan y-as om de focus te leggen op de verschillende slopes in het\n  # centrum van de data\n  coord_cartesian(ylim = c(15000, 18000)) +\n  # Plot een random sample van rijen van  de simulatie\n  # als grijze semi-transparante lijnen\n  geom_abline(\n    aes(intercept = intercept, slope = temp), \n    data = sample_n(fits, n_draws), \n    color = color_draw, \n    alpha = alpha_level\n  ) + \n  # Plot de gemiddelde waarden van onze parameters in blauw\n  # dit correspondeert met de coefficienten die we terugkregen van onze \n  # modelsamenvatting\n  geom_abline(\n    intercept = mean(fits$intercept), \n    slope = mean(fits$temp), \n    size = 1, \n    color = color_mean\n  ) +\n  geom_point() + \n  # definieer de aslabels en de titel van de plot\n  labs(x = 'Gemiddelde dagelijkse temperatuur (Graden Celsius)', \n       y = 'Dagelijkse totale aantal stappen' , \n       title = 'Visualisatie of 500 regressie lijnnen van de posterior eistributie')\n```\n\n::: {.cell-output-display}\n![](regressie-en-zo_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\nDe gemiddelde helling (weergegeven in de grafiek en ook terug te vinden in de modelsamenvatting hierboven) van de temperatuur is 26,8. Maar het plotten van samples uit de posterior verdeling maakt duidelijk dat er nogal wat onzekerheid is over de grootte van deze relatie! Sommige van de hellingen uit de verdeling zijn negatief - zoals we zagen in onze berekening van de onzekerheidsintervallen hierboven. In essentie is er een \"gemiddelde\" coëfficiëntschatting, maar wat het Bayesiaanse raamwerk heel goed doet (via de posterior verdelingen) is extra informatie verschaffen over de onzekerheid van onze schattingen.\n\n## Posterior voorspellingscontroles\nEen laatste manier om grafieken te gebruiken om ons model te begrijpen is door gebruik te maken van posterior predictive checks. Ik hou van deze intuïtieve manier om de logica achter deze reeks technieken uit te leggen: \"Het idee achter posterior predictive checking is simpel: als een model een goede fit is, moeten we het kunnen gebruiken om gegevens te genereren die veel lijken op de gegevens die we hebben waargenomen. De gegenereerde gegevens worden de posterior predictive distributie genoemd, dat is de verdeling van de uitkomstvariabele (dagelijks totaal aantal stappen in ons geval) die wordt geïmpliceerd door een model (het regressiemodel dat hierboven is gedefinieerd). Het gemiddelde van deze verdeling wordt weergegeven in de bovenstaande uitvoer van het regressieoverzicht, met de naam mean_PPD.\n\nEr zijn vele soorten visualisaties die men kan maken om posterieure voorspellende controles uit te voeren. Wij zullen één zo'n analyse uitvoeren (voor meer informatie over dit onderwerp), die het gemiddelde van onze uitkomstvariabele (dagelijks totaal aantal stappen) in onze oorspronkelijke dataset en de posterior predictive distributie van ons regressie model. \n\nDe code is rechttoe rechtaan.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# posterior predictive checks\n# https://mc-stan.org/bayesplot/reference/pp_check.html\n# http://mc-stan.org/rstanarm/reference/pp_check.stanreg.html\n\n# Het idee achter posterior predictive checking is eenvoudig: als een model een goede  \n# fit heeft dan moeten we data kunnen genereren die erg lijken op de data die we hebben geobserveerd.\n#  Om die data te genereren voor posterior predictive checks (PPCs), simuleren we die van de posterior predictive distributie. \n\n# posterior predictive check - voor meer informatie zie:\n# https://mc-stan.org/bayesplot/reference/pp_check.html\n# http://mc-stan.org/rstanarm/reference/pp_check.stanreg.html\npp_check(fit_1, \"stat\")\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](regressie-en-zo_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\nWe kunnen zien dat het gemiddelde van onze dagelijkse stappen variabele in de originele dataset in principe in het midden van de posterior voorspellende distributie valt. Volgens deze analyse \"genereert ons regressiemodel gegevens die veel lijken op de gegevens die we hebben geobserveerd!\"\n\n## Het model gebruiken om voorspellingen te doen met nieuwe gegevens\nTenslotte zullen we het model gebruiken om voorspellingen te doen over het aantal stappen per dag, gebaseerd op een specifieke waarde van de gemiddelde dagtemperatuur. In *Regression and Other Stories* bespreken de auteurs in hoofdstuk 9 hoe een Bayesiaans regressiemodel kan worden gebruikt om voorspellingen te doen op een aantal verschillende manieren, waarbij telkens verschillende niveaus van onzekerheid in de voorspellingen worden opgenomen. Wij zullen elk van deze methoden achtereenvolgens toepassen.\n\nVoor elk van de onderstaande methoden zullen we het gemiddelde aantal stappen per dag voorspellen wanneer de temperatuur 10 graden Celsius bedraagt. We kunnen een nieuw dataframe opzetten dat we zullen gebruiken om de modelvoorspellingen te verkrijgen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Gebruik het model om voorspellingen te doen\n# defineer nieuwe data van waaruit we deze voorspellingen maken \n# we doen voorspellingen voor het geval de gemiddelde dagtemperatuur 10 graden Celsius is for when the average daily temperature \nnew <- data.frame(temp = 10)\n```\n:::\n\n\n## Puntvoorspellingen met behulp van de samenvattingen van de afzonderlijke waardecoëfficiënten van de posterieure verdelingen\nDe eerste benadering komt overeen met die welke we zouden gebruiken bij een klassieke regressieanalyse. We gebruiken gewoon de puntschattingen uit de modelsamenvatting, voegen de nieuwe temperatuur in waarvoor we een voorspelling willen, en produceren onze voorspelling in de vorm van een enkel getal. We kunnen dit doen met de predict functie in R, of door de coëfficiënten uit onze modelsamenvatting te vermenigvuldigen. Beide methoden leveren dezelfde voorspelling op:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# gebruik simpel de puntsamenvatting van de posterio distributie \n# voor de modelcoefficienten (van de modelsamenvatting van hierboven)\ny_point_est <- predict(fit_1, newdata = new)\n# zelfde predictie \"met de hand\"\ny_point_est_2 <- mean(sims[,1]) + mean(sims[,2])*new\n```\n:::\n\n\n\nBeide leveren een puntvoorspelling van 16483.71.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# ze zijn hetzelfde \npredict(fit_1, newdata = new)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      1 \n16485.1 \n```\n:::\n\n```{.r .cell-code}\nmean(sims[,1]) + mean(sims[,2])*new\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     temp\n1 16485.1\n```\n:::\n:::\n\n\n## Lineaire voorspellingen met onzekerheid (in de interceptie + temperatuurcoëfficiënten)\nWe kunnen echter genuanceerder zijn in onze voorspelling van het dagelijkse totale aantal stappen. Het hierboven berekende regressiemodel geeft 4.000 simulaties voor drie parameters - de intercept, de temperatuurcoëfficiënt, en sigma (de standaardafwijking van de residuen).\n\nDe volgende methode is geïmplementeerd in *rstanarm* met de *posterior_linpred* functie, en we kunnen deze gebruiken om de voorspellingen direct te berekenen. We kunnen hetzelfde resultaat ook \"met de hand\" berekenen met behulp van de matrix van simulaties uit de posterior verdeling van onze coëfficiëntschattingen. Bij deze aanpak wordt gewoon de temperatuur ingevoerd waarvoor wij voorspellingen willen (10 graden Celsius) en wordt voor elk van de simulaties het intercept opgeteld bij de temperatuurcoëfficiënt maal 10. Beide methoden leveren dezelfde vector van 4.000 voorspellingen op:   \n\n\n::: {.cell}\n\n```{.r .cell-code}\n# lineaire predictor met onzekerheid met gebruikmaking van posterior_linpred\n\ny_linpred <- posterior_linpred(fit_1, newdata = new)\n# uitrekenen \"met de hand\" \n# we gebruiken de sims matrix die we hierboven definieerden \n# sims <- as.matrix(fit_1)\ny_linpred_2 <- sims[,1] + (sims[,2]*10)  \n```\n:::\n\n\nDat geeft dezelfde resultaten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# check - ze zijn hetzelfde!\nplot(y_linpred,y_linpred_2)\n```\n\n::: {.cell-output-display}\n![](regressie-en-zo_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncor.test(y_linpred, y_linpred_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  y_linpred and y_linpred_2\nt = Inf, df = 3998, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 1 1\nsample estimates:\ncor \n  1 \n```\n:::\n:::\n\n\n## Posterior Predictive Distributies met de onzekerheid in de coëfficiëntschattingen en in sigma\nDe laatste voorspellingsmethode voegt nog een extra laag van onzekerheid toe aan onze voorspellingen, door de posterior verdelingen voor sigma mee te nemen in de berekeningen. Deze methode is beschikbaar via de functie *posterior_predict*, en we gebruiken opnieuw onze matrix van 4.000 simulaties om een vector van 4.000 voorspellingen te berekenen. \n\nDe posterior predict methode volgt de aanpak van de *posterior_linpred* functie hierboven, maar voegt een extra foutterm toe gebaseerd op onze schattingen van sigma, de standaardafwijking van de residuen. De berekening zoals getoond in het \"met de hand\" gedeelte van de code hieronder maakt. Het maakt duidelijk waar de willekeurigheid in het spel komt, en vanwege deze willekeurigheid zullen de resultaten van de *posterior_predict* functie en de \"met de hand\" berekening niet overeenkomen tenzij we dezelfde seed instellen voordat we elke berekening uitvoeren. Beide methoden leveren een vector van 4.000 voorspellingen op.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# predictive distributie voor een nieuwe observatie met gebruik van posterior_predict\n\nset.seed(1)\ny_post_pred <- posterior_predict(fit_1, newdata = new)\n```\n:::\n\n\nOf \n\n::: {.cell}\n\n```{.r .cell-code}\n# uitrekenen \"met de hand\"\nn_sims <- nrow(sims)\nsigma <- sims[,3]\nset.seed(1)\ny_post_pred_2 <- as.numeric(sims[,1] + sims[,2]*10) + rnorm(n_sims, 0, sigma)\n```\n:::\n\n\nDan zien we dezelfde resultaten:\n\n::: {.cell}\n\n```{.r .cell-code}\n# check - ze zijn hetzelfde!\nplot(y_post_pred, y_post_pred_2)\n```\n\n::: {.cell-output-display}\n![](regressie-en-zo_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n\n```{.r .cell-code}\ncor.test(y_post_pred, y_post_pred_2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPearson's product-moment correlation\n\ndata:  y_post_pred and y_post_pred_2\nt = Inf, df = 3998, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 1 1\nsample estimates:\ncor \n  1 \n```\n:::\n:::\n\n\n## Visualisatie van de drie soorten voorspellingen\nLaten we een visualisatie maken die de resultaten weergeeft van de voorspellingen die we hierboven deden. We kunnen een enkele cirkel gebruiken om de puntvoorspelling van de regressiecoëfficiënten weer te geven in de modelsamenvatting, en histogrammen om de posterior verdelingen weer te geven die geproduceerd zijn door de lineaire voorspelling met onzekerheid (*posterior_linpred*) en posterior predictive distribution (*posterior_predict*) methoden die hierboven beschreven zijn.\n\nWe zetten eerst de vectoren van posterior verdelingen die we hierboven hebben gemaakt in een dataframe. We maken ook een dataframe met de enkele puntvoorspelling van onze lineaire voorspelling. Vervolgens stellen we ons kleurenpalet in (afkomstig uit het NineteenEightyR pakket) en maken dan de plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# creeer een dataframe die de waarden van de posterior distributies omvat \n# van de voorspellingen van de totaal aantal dagelijkse stappen bij 10 grade Celcius\npost_dists <- as.data.frame(rbind(y_linpred, y_post_pred)) %>% \n      setNames(c('prediction'))\npost_dists$pred_type <- c(rep('posterior_linpred', 4000),\n                          rep('posterior_predict', 4000))\ny_point_est_df = as.data.frame(y_point_est)\n```\n:::\n\n\nDat geeft de volgende plot:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# 70 en meer kleuren - via NineteenEightyR pakket\n# https://github.com/m-clark/NineteenEightyR\npal <- c('#FEDF37', '#FCA811', '#D25117', '#8A4C19', '#573420')\n\nggplot(data = post_dists, aes(x = prediction, fill = pred_type)) + \n  geom_histogram(alpha = .75, position=\"identity\") + \n  geom_point(data = y_point_est_df,\n             aes(x = y_point_est,\n                 y = 100,\n                 fill = 'Linear Point Estimate'),\n             color =  pal[2],\n             size = 4,\n             # alpha = .75,\n             show.legend = F) +\n  scale_fill_manual(name = \"Prediction Method\",\n                    values = c(pal[c(2,3,5)]),\n                    labels = c(bquote(paste(\"Lineaire Punt Schatting \", italic(\"(predict)\"))),\n                               bquote(paste(\"Lineaire Voorspelling met Onzekerheid \" , italic(\"(posterior_linpred)\"))),\n                               bquote(paste(\"Posterior Predictive Distributie \",  italic(\"(posterior_predict)\"))))) +\n  # set the plot labels and title\n  labs(x = \"Predicted Daily Total Step Count\", \n       y = \"Aantal\", \n       title = 'Onzekerheid in Posterior Predictie Methode')   +\n  theme_bw()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n```\n:::\n\n::: {.cell-output-display}\n![](regressie-en-zo_files/figure-html/unnamed-chunk-24-1.png){width=672}\n:::\n:::\n\n\nDeze grafiek is zeer informatief en maakt duidelijk hoe groot de onzekerheid is die we voor elk van onze voorspellingsmethoden krijgen. Hoewel alle drie voorspellingsmethoden op dezelfde plaats op de x-as gecentreerd zijn, verschillen zij sterk wat betreft de onzekerheid rond de voorspellingsramingen.\n\nDe puntvoorspelling is een enkele waarde en bevat als zodanig geen onzekerheid. De lineaire voorspelling met onzekerheid, die rekening houdt met de posterior verdeling van onze interceptie- en temperatuurcoëfficiënten, heeft een zeer scherpe piek, waarbij de modelschattingen binnen een relatief klein bereik variëren. De posterior predictive distributie varieert veel meer, met het laagste bereik van de verdeling onder nul, en het hoogste bereik van de verdeling boven 40.000!\n\n## Samenvatting en conclusie\nIn dit artikel hebben we een eenvoudig model gemaakt met behulp van het *rstanarm* pakket in R, om te leren over Bayesiaanse regressie analyse. We gebruikten een dataset bestaande uit mijn geschiedenis van dagelijkse totale stappen, en bouwden een regressie model om het dagelijkse aantal stappen te voorspellen uit de dagelijkse gemiddelde temperatuur in graden Celsius. In tegenstelling tot de gewone kleinste kwadraten benadering die puntschattingen van modelcoëfficiënten oplevert, geeft de Bayesiaanse regressie posterior verdelingen van de coëfficiëntschattingen. Wij hebben een aantal verschillende samenvattingen en visualisaties van deze posterior verdelingen gemaakt om de coëfficiënten en de Bayesiaanse benadering in het algemeen te begrijpen - \nA) het gebruik van het bayesplot pakket om de posterior verdelingen van onze coëfficiënten te visualiseren    \nB) het plotten van 500 hellingen van de posterior verdeling, en   \nC) het uitvoeren van een controle van de posterior predictive distributie.\n\n",
    "supporting": [
      "regressie-en-zo_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}