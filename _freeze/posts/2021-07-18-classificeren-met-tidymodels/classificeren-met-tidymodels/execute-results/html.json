{
  "hash": "eae357e816a63d3a474e9e102cd17c3f",
  "result": {
    "markdown": "---\ntitle: \"Classificeren met Tidymodels\"\ndescription: |\n    Dit is bewerking van een blog over classificeren met het pakket Tidymodels die Rahul Raoniar in Towards data science schreef.\nauthor: \"Rahul Raoniar, bewerking Harrie Jonkman\"\ndate: \"07-05-2021\"\ncategories: [analyse]\nimage: \"Screenshot1.png\"\n---\n\n\n### Inleiding\nEen gids om stap voor stap een logissche regressie uit te voeren met gebruik van het `tidymodels` pakket\n\nDit is bewerking van een blog die [Rahul Raoniar, Towards data science](https://towardsdatascience.com/modelling-binary-logistic-regression-using-tidymodels-library-in-r-part-1-c1bdce0ac055) begin 2021 schreef. \n\n\nIn de wereld van 'supervised machine learning' worden vaak twee soorten analyses uitgevoerd. De ene heet regressie (voorspellen van continue waarden), de andere heet classificatie (voorspellen van discrete waarden). In deze blog geef ik een voorbeeld van een binair classificatiealgoritme, \"**Binaire Logistische Regressie**\" genaamd. Dat valt onder de Binomiale familie met een logit koppelingsfunctie. Binaire logistische regressie wordt gebruikt voor het voorspellen van binaire klassen. Bijvoorbeeld in gevallen waarin je ja/nee, winst/verlies, negatief/positief, waar/onwaar enzovoort wilt voorspellen.\n\n*Deze blog leidt jou door een proces van hoe het 'tidymodels'-pakket te gebruiken om een model toe te passen en te evalueren met heel weinig en eenvoudige stappen.* \n\n\n### Achtergrond van de data\nIn dit voorbeeld maak je gebruik maken van de **Pima Indian Diabetes 2** data, verkregen uit de UCI Repository van de machine learning data (*Newman et al. 1998*).\n\nDeze data zijn oorspronkelijk afkomstig van het 'National Institute of Diabetes and Digestive and Kidney Diseases'. Het doel van de dataset is diagnostisch te voorspellen of een patiënt al dan niet diabetes heeft, op basis  bepaalde diagnostische metingen die in de dataset zijn opgenomen. Bij de selectie van deze data uit een grotere databank werden verschillende beperkingen opgelegd. In het bijzonder zijn alle patiënten hier vrouwen van ten minste 21 jaar oud van Pima Indiaanse afkomst.\nDe Pima Indian Diabetes 2-data is de verfijnde versie (alle ontbrekende waarden zijn toegewezen als NA) van de Pima Indian diabetes-gegevens. De dataset bevat de volgende onafhankelijke en afhankelijke variabelen.\n\n*Onafhankelijke variabelen (met symbool: O)*\n- O1: pregnant: Aantal keren zwanger    \n- O2: glucose: Plasma glucose concentratie (glucose tolerantie test)    \n- O3: pressure: Diastolische bloed druk (mm Hg)    \n- O4: triceps: Triceps huidplooidikte (mm)   \n- O5: insulin: 2-uur serum insuline (mu U/ml)   \n- O6: mass: Body mass index (gewicht in kg/(lengte in m)\\²)    \n- O7: pedigree: Diabetes pedigree functie    \n- O8: age: Leeftijd (jaren)   \n\n*Dependent Variable (met symbool: A)*   \n- A1: diabetes: diabetes geval (pos/neg)    \n\n### Doel van de modellering\n- aanpassen van een binair logistisch regressie-machineleermodel met behulp van de bibliotheek `tidymodels`   \n- het testen van de voorspellingskracht van het getrainde model (evaluatie van het model) op de ongeziene/geteste dataset met behulp van verschillende evaluatiemetrieken. \n\n### Bibliotheken en Datasets laden\n**Stap1:** Eerst moeten we de volgende pakketten worden geïnstalleerd met de `install.packages( )` functie (als ze al niet zijn geïnstalleerd en ze laden met de `library( )` functie.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlbench)     # voor de PimaIndiansDiabetes2 dataset\nlibrary(tidymodels)  # voor modelpreparatie en fitten van modellen\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidymodels' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Attaching packages -------------------------------------- tidymodels 0.2.0 --\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nv broom        0.8.0     v recipes      0.2.0\nv dials        1.0.0     v rsample      0.1.1\nv dplyr        1.0.9     v tibble       3.1.7\nv ggplot2      3.3.6     v tidyr        1.2.0\nv infer        1.0.2     v tune         0.2.0\nv modeldata    0.1.1     v workflows    0.2.6\nv parsnip      1.0.0     v workflowsets 0.2.1\nv purrr        0.3.4     v yardstick    1.0.0\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'broom' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'dials' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'scales' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'dplyr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'ggplot2' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'infer' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'parsnip' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'recipes' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tibble' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tidyr' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'tune' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'workflows' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'workflowsets' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'yardstick' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n-- Conflicts ----------------------------------------- tidymodels_conflicts() --\nx purrr::discard() masks scales::discard()\nx dplyr::filter()  masks stats::filter()\nx dplyr::lag()     masks stats::lag()\nx recipes::step()  masks stats::step()\n* Use tidymodels_prefer() to resolve common conflicts.\n```\n:::\n:::\n\n\n**Stap2:** Vervolgens moet je de dataset binnen halen uit het `mlbench` pakket met behulp van de `data( )` functie.\n\nNa het laden van de data, is de volgende essentiële stap het uitvoeren van een verkennende data-analyse, die zal helpen bij het vertrouwd raken met de data. Gebruik de `head( )` functie om de bovenste zes rijen van de data te bekijken.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(PimaIndiansDiabetes2)\nhead(PimaIndiansDiabetes2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pregnant glucose pressure triceps insulin mass pedigree age diabetes\n1        6     148       72      35      NA 33.6    0.627  50      pos\n2        1      85       66      29      NA 26.6    0.351  31      neg\n3        8     183       64      NA      NA 23.3    0.672  32      pos\n4        1      89       66      23      94 28.1    0.167  21      neg\n5        0     137       40      35     168 43.1    2.288  33      pos\n6        5     116       74      NA      NA 25.6    0.201  30      neg\n```\n:::\n:::\n\n\nDe Diabetes-gegevensreeks telt 768 waarnemingen en negen variabelen. De eerste acht variabelen zijn van het numerieke type en de afhankelijke/output variabele (diabetes) is een factor/categorische variabele. Het is ook merkbaar dat veel variabelen `NA` waarden bevatten (missende waarde). Onze volgende taak is het de gegevens te verfijnen/wijzigen, zodat ze compatibel worden met het modelleeralgoritme. Eerst nog eens beter naar de data kijken.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Een blik op de datastructuur\nglimpse(PimaIndiansDiabetes2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 768\nColumns: 9\n$ pregnant <dbl> 6, 1, 8, 1, 0, 5, 3, 10, 2, 8, 4, 10, 10, 1, 5, 7, 0, 7, 1, 1~\n$ glucose  <dbl> 148, 85, 183, 89, 137, 116, 78, 115, 197, 125, 110, 168, 139,~\n$ pressure <dbl> 72, 66, 64, 66, 40, 74, 50, NA, 70, 96, 92, 74, 80, 60, 72, N~\n$ triceps  <dbl> 35, 29, NA, 23, 35, NA, 32, NA, 45, NA, NA, NA, NA, 23, 19, N~\n$ insulin  <dbl> NA, NA, NA, 94, 168, NA, 88, NA, 543, NA, NA, NA, NA, 846, 17~\n$ mass     <dbl> 33.6, 26.6, 23.3, 28.1, 43.1, 25.6, 31.0, 35.3, 30.5, NA, 37.~\n$ pedigree <dbl> 0.627, 0.351, 0.672, 0.167, 2.288, 0.201, 0.248, 0.134, 0.158~\n$ age      <dbl> 50, 31, 32, 21, 33, 30, 26, 29, 53, 54, 30, 34, 57, 59, 51, 3~\n$ diabetes <fct> pos, neg, pos, neg, pos, neg, pos, neg, pos, pos, neg, pos, n~\n```\n:::\n:::\n\n\n### Voorbereiding van de gegevens\nDe eerste stap is het verwijderen van data rijen met `NA` waarden met behulp van `na.omit( )` functie. De volgende stap is nogmaals het controleren van de gegevens met behulp van de `glimpse( )` functie.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDiabetes <- na.omit(PimaIndiansDiabetes2) #weghalen van NA waarden\nglimpse(Diabetes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 392\nColumns: 9\n$ pregnant <dbl> 1, 0, 3, 2, 1, 5, 0, 1, 1, 3, 11, 10, 1, 13, 3, 3, 4, 4, 3, 9~\n$ glucose  <dbl> 89, 137, 78, 197, 189, 166, 118, 103, 115, 126, 143, 125, 97,~\n$ pressure <dbl> 66, 40, 50, 70, 60, 72, 84, 30, 70, 88, 94, 70, 66, 82, 76, 5~\n$ triceps  <dbl> 23, 35, 32, 45, 23, 19, 47, 38, 30, 41, 33, 26, 15, 19, 36, 1~\n$ insulin  <dbl> 94, 168, 88, 543, 846, 175, 230, 83, 96, 235, 146, 115, 140, ~\n$ mass     <dbl> 28.1, 43.1, 31.0, 30.5, 30.1, 25.8, 45.8, 43.3, 34.6, 39.3, 3~\n$ pedigree <dbl> 0.167, 2.288, 0.248, 0.158, 0.398, 0.587, 0.551, 0.183, 0.529~\n$ age      <dbl> 21, 33, 26, 53, 59, 51, 31, 33, 32, 27, 51, 41, 22, 57, 28, 2~\n$ diabetes <fct> neg, pos, pos, pos, pos, pos, pos, neg, pos, neg, pos, pos, n~\n```\n:::\n:::\n\n\nDe uiteindelijke (voorbereide) gegevens bevatten 392 waarnemingen en 9 kolommen. De onafhankelijke variabelen zijn van het type numeriek/dubbel, terwijl de afhankelijke/uitgaande binaire variabele van het type factor/categorie is (neg/ pos).\n\n### Gegevensniveaus\nWe kunnen het referentieniveau van de afhankelijke variabele controleren met de functie `levels( )`. We kunnen zien dat het referentieniveau *neg* is (het allereerste niveau).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlevels(Diabetes$diabetes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"neg\" \"pos\"\n```\n:::\n:::\n\n\n### Instellen referentieniveau\nVoor een betere interpretatie (later voor het uitzetten van de ROC curve) moeten we het referentieniveau van onze afhankelijke variabele \"diabetes\" op *positief (pos)* zetten met de `relevel( )` functie.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nDiabetes$diabetes <- relevel(Diabetes$diabetes, ref = \"pos\")\nlevels(Diabetes$diabetes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"pos\" \"neg\"\n```\n:::\n:::\n\n\n### Splitsing training en testset\nDe volledige dataset wordt in het algemeen opgesplitst in 75% train en 25% test data set (algemene vuistregel). 75% van de trainingsdata wordt gebruikt om het model te trainen, terwijl de overige 25% wordt gebruikt om te controleren hoe het model generaliseerde op ongeziene/test data set.\n\nOm een split object te maken kun je de `initial_split( )` functie gebruiken waar je de dataset, proportie en een strata argument voor moet opgeven. Door de afhankelijke variabele in het strata-attribuut op te geven, wordt gestratificeerde steekproeftrekking uitgevoerd. Gestratificeerde steekproeftrekking is nuttig als je afhankelijke variabele een ongelijke klasse heeft.\n\nDe volgende stap is het aanroepen van de `training( )` en `testing( )` functies op het split object (d.w.z. `diabetes_split`) om de trainings- (`diabetes_train`) en test- (`diabetes_test`) datasets op te slaan.\n\nDe training set bevat 295 waarnemingen, terwijl de test set 97 waarnemingen bevat.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\n# Creëer datasplit voor training en test\ndiabetes_split <- initial_split(Diabetes,\n                                prop = 0.75,\n                                strata = diabetes)\n\n# Creëer trainingsdata\ndiabetes_train <- diabetes_split %>%\n                    training()\n\n# Creëer testdata\ndiabetes_test <- diabetes_split %>%\n                    testing()\n# Aantal rijen in trainings- en testset\nnrow(diabetes_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 293\n```\n:::\n\n```{.r .cell-code}\nnrow(diabetes_test)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 99\n```\n:::\n:::\n\n\n### Fitten van logistische regressie\nJe kunt met `tidymodels` elk type model pasklaar maken met behulp van de volgende stappen.\nl\n*Stap 1*: roep de modelfunctie op: hier gebruiken we `logistic_reg( )` omdat we een logistisch regressiemodel willen draaien.   \n\n*Stap 2*: gebruik de `set_engine( )` functie om de familie van het model op te geven. We geven het `glm` argument op, omdat logistische regressie onder de 'Generalized Linear Regression'-familie valt.   \n\n*Stap 3*: gebruik de `set_mode( )` functie en geef het type model op dat je wilt toepassen. Hier willen we pos vs neg classificeren, dus het is een *classificatie*.   \n\n*Stap 4*: Vervolgens moet je de `fit( )` functie gebruiken om het model te fitten en daarbinnen moet je de formule notatie en de dataset (`diabetes_train`) opgeven.\n\n*plus notatie →*\n`diabetes ~ ind_variable 1 + ind_variable 2 + …….so on`   \n\n*tilde punt notatioe →*   \ndiabetes~.\nbetekent dat diabetes wordt voorspeld door de rest van de variabelen in het gegevensbestand (d.w.z. alle onafhankelijke variabelen), behalve de afhankelijke variabele, d.w.z. diabetes.\n\nNa het draaien van het model is de volgende stap het genereren van de modeloverzichtstabel. Je kunt een mooie tabel maken met behulp van de `tidy( )` functie van de `broom` bibliotheek (die is ingebouwd in de `tidymodels` bibliotheek). De gerapporteerde coëfficiënten zijn in log-odds termen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfitted_logistic_model<- logistic_reg() %>%\n        # Set the engine\n        set_engine(\"glm\") %>%\n        # Set the mode\n        set_mode(\"classification\") %>%\n        # Fit the model\n        fit(diabetes~., data = diabetes_train)\ntidy(fitted_logistic_model)    # Generate Summary Table\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 x 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept) 10.3        1.47       6.96   3.38e-12\n2 pregnant    -0.0788     0.0647    -1.22   2.24e- 1\n3 glucose     -0.0390     0.00681   -5.72   1.04e- 8\n4 pressure     0.000634   0.0144     0.0440 9.65e- 1\n5 triceps     -0.0295     0.0208    -1.42   1.56e- 1\n6 insulin     -0.00166    0.00163   -1.02   3.09e- 1\n7 mass        -0.0587     0.0328    -1.79   7.37e- 2\n8 pedigree    -1.42       0.524     -2.71   6.65e- 3\n9 age         -0.0152     0.0209    -0.724  4.69e- 1\n```\n:::\n:::\n\n\n**Opgelet:** *Het teken en de waarde van de coëfficiënten veranderen afhankelijk van de referentie die u voor de afhankelijke variabele hebt ingesteld (in ons geval is pos het referentieniveau) en de waarneming die u op basis van de aselecte steekproefselectie in de opleidingssteekproef hebt opgenomen [bovenstaande resultaten zijn slechts een voorbeeld].*\n\nDe interpretatie van coëfficiënten in de log-odds term heeft niet veel zin als je die moet rapporteren in je artikel of publicatie. Daarom werd het begrip odds ratio geïntroduceerd.\n\nDe ODDS is de verhouding van de kans dat een gebeurtenis zich voordoet tot de kans dat de gebeurtenis zich niet voordoet. Wanneer we een verhouding van twee zulke kansen nemen, noemen we dat Odds Ratio.\n\n\n![Odds ratio](Screenshot1.png)\n\n\nWiskundig kan men de odds ratio berekenen door de exponent van de geschatte coëfficiënten te nemen. Je kunt bijvoorbeeld direct de odds ratio's van de coëfficiënten krijgen door de *exponentiate = True* mee te geven in de `tidy( )` functie.\n\nHet resultaat is alleen afhankelijk van de steekproeven die we hebben verkregen tijdens het splitsen. Je kunt een ander resultaat krijgen (odds ratio waarden).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(fitted_logistic_model, exponentiate = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 9 x 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept) 28591.      1.47       6.96   3.38e-12\n2 pregnant        0.924   0.0647    -1.22   2.24e- 1\n3 glucose         0.962   0.00681   -5.72   1.04e- 8\n4 pressure        1.00    0.0144     0.0440 9.65e- 1\n5 triceps         0.971   0.0208    -1.42   1.56e- 1\n6 insulin         0.998   0.00163   -1.02   3.09e- 1\n7 mass            0.943   0.0328    -1.79   7.37e- 2\n8 pedigree        0.242   0.524     -2.71   6.65e- 3\n9 age             0.985   0.0209    -0.724  4.69e- 1\n```\n:::\n:::\n\n\n### Significante kansen\nDe tabel geproduceerd door `tidy( )` functie kan worden gefilterd. Hier hebben we de variabelen uitgefilterd waarvan de p-waarden lager zijn dan 0.05 (5%) significant niveau. Voor onze steekproef hebben glucose en massa een significante invloed op diabetes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(fitted_logistic_model, exponentiate = TRUE) %>%\n  filter(p.value < 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 x 5\n  term         estimate std.error statistic  p.value\n  <chr>           <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept) 28591.      1.47         6.96 3.38e-12\n2 glucose         0.962   0.00681     -5.72 1.04e- 8\n3 pedigree        0.242   0.524       -2.71 6.65e- 3\n```\n:::\n:::\n\n\n### Model voorspelling\n### Voorspelling van de testgegevensklasse\nDe volgende stap is het genereren van de testvoorspellingen die we kunnen gebruiken voor de evaluatie van het model. Om de klassevoorspelling (pos/neg) te genereren kunnen wij de predict-functie gebruiken en het *getrainde modelobject, de testdataset* en het type opgeven, dat hier \"klasse\" is, aangezien wij de klassevoorspelling willen, geen waarschijnlijkheden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Class prediction\npred_class <- predict(fitted_logistic_model,\n                      new_data = diabetes_test,\n                      type = \"class\")\n\npred_class[1:5,]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 1\n  .pred_class\n  <fct>      \n1 neg        \n2 pos        \n3 neg        \n4 pos        \n5 pos        \n```\n:::\n:::\n\n\n### Testdata klasse waarschijnlijkheden\nWe kunnen ook voorspellingen genereren voor de klassenwaarschijnlijkheden door het argument \"prob\" in het type-attribuut mee te geven.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Voorspelling waarschijnlijkheden\npred_proba <- predict(fitted_logistic_model,\n                      new_data = diabetes_test,\n                      type = \"prob\")\n\npred_proba[1:5,]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  .pred_pos .pred_neg\n      <dbl>     <dbl>\n1     0.164     0.836\n2     0.536     0.464\n3     0.279     0.721\n4     0.739     0.261\n5     0.831     0.169\n```\n:::\n:::\n\n\n### Voorbereiding van de uiteindelijke gegevens voor de evaluatie van het model\nDe volgende stap is het voorbereiden van een gegevensframe dat de kolom diabetes uit de oorspronkelijke testdataset, de voorspelde klasse en de klassevoorspellingswaarschijnlijkheid bevat. We gaan dit dataframe gebruiken voor de evaluatie van het model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes_results <- diabetes_test %>%\n  select(diabetes) %>%\n  bind_cols(pred_class, pred_proba)\n\ndiabetes_results[1:5, ]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   diabetes .pred_class .pred_pos .pred_neg\n19      neg         neg 0.1640730 0.8359270\n21      neg         pos 0.5360718 0.4639282\n26      pos         neg 0.2786670 0.7213330\n32      pos         pos 0.7389338 0.2610662\n55      neg         pos 0.8311350 0.1688650\n```\n:::\n:::\n\n\n\n### Modelevaluatie\n### Confusiematrix\n\nWe kunnen een confusiematrix genereren met de `conf_mat( )`-functie door het uiteindelijke dataframe, `diabetes_results`, de waarheidskolom, `diabetes` en `voorspelde klasse (.pred_class)` in het schattingsattribuut op te geven.\n\nUit de confusiematrix blijkt dat de testdataset 65 gevallen van negatieve (neg) en 32 gevallen van positieve (pos) waarnemingen bevat. Het getrainde model classificeert 61 negatieven (neg) en 18 positieven (pos) accuraat.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_mat(diabetes_results, truth = diabetes,\n         estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          Truth\nPrediction pos neg\n       pos  21  12\n       neg  12  54\n```\n:::\n:::\n\n\nWe kunnen ook het `yardstick` pakket gebruiken dat bij het `tidymodels` pakket hoort om verschillende evaluatie metrieken te genereren voor de testdata set.\n\n### Nauwkeurigheid\nWe kunnen de classificatienauwkeurigheid berekenen met de `accuracy( )`-functie door het uiteindelijke dataframe, `diabetes_results`, de waarheidskolom, `diabetes` en `voorspelde klasse (.pred_class)` in het schattingsattribuut op te geven. De classificatienauwkeurigheid van het model op de testdataset is ongeveer 81,4%.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naccuracy(diabetes_results, truth = diabetes,\n         estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.758\n```\n:::\n:::\n\n\n### Sensitiviteit\nDe *sensitiviteit* van een classificator is de verhouding tussen het aantal dat correct als positief wordt geïdentificeerd (TP) en het aantal dat daadwerkelijk positief is (FN+TP).\n\n*Sensitivity = TP / FN+TP*\n\n\nDe geschatte sensitiviteitswaarde is 0,562, wat wijst op een slechte detectie van positieve klassen in de testdataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsens(diabetes_results, truth = diabetes,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 sens    binary         0.636\n```\n:::\n:::\n\n\n### Specificiteit\n*Specificiteit* van een classificator is de verhouding tussen het aantal dat correct als negatief werd geclassificeerd (TN) en het aantal dat werkelijk negatief was (FP+TN).\n\n*Specificity = TN/FP+TN*\n\nDe geschatte specificiteitswaarde is 0,938, wat wijst op een algemeen goede detectie van negatieve klassen in de testdataset.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nspec(diabetes_results, truth = diabetes,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 spec    binary         0.818\n```\n:::\n:::\n\n\n### Precisie\nHoeveel van alle positieven werden correct als positief geclassificeerd?\n\n\n*Precisie = TP/TP+FP*\n\nDe geschatte *precisie* waarde is 0.818.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprecision(diabetes_results, truth = diabetes,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric   .estimator .estimate\n  <chr>     <chr>          <dbl>\n1 precision binary         0.636\n```\n:::\n:::\n\n\n### Recall\n*Recall* en sensitiviteit zijn hetzelfde.\n\n*Recall = TP / FN+TP*\n\nDe geschatte recall-waarde is 0.562.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrecall(diabetes_results, truth = diabetes,\n      estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 recall  binary         0.636\n```\n:::\n:::\n\n\n### F-maat\n*F-maat* is een gewogen harmonisch gemiddelde van precisie en recall met de beste score 1 en de slechtste score 0. De F-maatscore geeft het evenwicht tussen precisie en recall weer. De F1-score is ongeveer 0,667, wat betekent dat het getrainde model een classificatiekracht van 66,7% heeft.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nf_meas(diabetes_results, truth = diabetes,\n       estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 f_meas  binary         0.636\n```\n:::\n:::\n\n\n### Kappa\nCohen Kappa geeft informatie over hoeveel beter een model is dan de willekeurige classificator. Kappa kan gaan van -1 tot +1. De waarde <0 betekent geen overeenstemming, terwijl 1,0 een perfecte overeenstemming aangeeft. Uit de geschatte kappastatistieken bleek een matige overeenkomst.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nkap(diabetes_results, truth = diabetes,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 kap     binary         0.455\n```\n:::\n:::\n\n\n### Matthews Correlatie Coefficient (MCC)\nDe *Matthews correlatiecoëfficiënt (MCC)* wordt gebruikt als maatstaf voor de kwaliteit van een binaire classificator. De waarde varieert van -1 tot +1.\n\nMCC: -1 wijst op totale onenigheid\nMCC: 0 wijst op geen overeenstemming\nMCC: +1 wijst op totale overeenstemming\n\nUit de geschatte MCC-statistieken bleek een matige overeenstemming.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmcc(diabetes_results, truth = diabetes,\n    estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 mcc     binary         0.455\n```\n:::\n:::\n\n\n### Evaluatiematen genereren\nWe kunnen de `custom_metrics( )`-functie gebruiken om verschillende metrieken tegelijk te genereren.\n\n*Stap 1:* laat eerst zien wat je wilt laten zien door `metric_set( )` te gebruiken\n*Step 2:* gebruik de`custom_metrics( )` functie en betrek dit op de `diabetes_results` dataframe, `diabaets` kolom en op de voorspelde klasse (`.pred_class`).\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncustom_metrics <- metric_set(accuracy, sens, spec, precision, recall, f_meas, kap, mcc)\ncustom_metrics(diabetes_results,\n               truth = diabetes,\n               estimate = .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 x 3\n  .metric   .estimator .estimate\n  <chr>     <chr>          <dbl>\n1 accuracy  binary         0.758\n2 sens      binary         0.636\n3 spec      binary         0.818\n4 precision binary         0.636\n5 recall    binary         0.636\n6 f_meas    binary         0.636\n7 kap       binary         0.455\n8 mcc       binary         0.455\n```\n:::\n:::\n\n\n### ROC-AUC\nROC-AUC is a performance measurement for the classification problem at various thresholds settings. ROC_AUC tells how much the model is capable of distinguishing between classes. The trained logistic regression model has a ROC-AUC of 0.921 indicating overall good predictive performance.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nroc_auc(diabetes_results,\n        truth = diabetes,\n        .pred_pos)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.828\n```\n:::\n:::\n\n\n### ROC-curve\nROC-AUC is een evaluatiemaat voor het classificatieprobleem bij verschillende drempelinstellingen. ROC-AUC geeft aan in welke mate het model in staat is een onderscheid te maken tussen de klassen. Het getrainde logistische regressiemodel heeft een ROC-AUC van 0,921, wat wijst op een algemeen goede voorspellende prestatie.\n\n\nDe ROC-curve wordt uitgezet met TPR (Sensitiviteit) tegen de FPR/ (1- Specificiteit), waarbij Sensitiviteit op de y-as staat en 1-Specificiteit op de x-as. Een lijn wordt diagonaal getrokken om de 50-50 verdeling van de grafiek aan te geven. Als de kromme dichter bij de lijn ligt, is de prestatie van de classificeerder lager en dan niet beter dan een toevallige gok.\n\nJe kunt een ROC Curve genereren met de `roc_curve( )` functie waarbij je de waarheidskolom (`diabetes`) en de voorspelde kansen voor de positieve klasse (`.pred_pos`) moet opgeven.\n\nOns model heeft een ROC-AUC score van 0.921 wat aangeeft dat het een goed model is dat onderscheid kan maken tussen patiënten met diabetes en zonder diabetes.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiabetes_results %>%\n  roc_curve(truth = diabetes, .pred_pos) %>%\n  autoplot()\n```\n\n::: {.cell-output-display}\n![](classificeren-met-tidymodels_files/figure-html/unnamed-chunk-25-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Schatting van verschillende evaluatiematenmet behulp van het caret-pakket\nlibrary(caret)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: package 'caret' was built under R version 4.1.3\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLoading required package: lattice\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'caret'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following objects are masked from 'package:yardstick':\n\n    precision, recall, sensitivity, specificity\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:purrr':\n\n    lift\n```\n:::\n\n```{.r .cell-code}\nconfusionMatrix(diabetes_results$.pred_class,\n                diabetes_results$diabetes,\n                positive=\"pos\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nConfusion Matrix and Statistics\n\n          Reference\nPrediction pos neg\n       pos  21  12\n       neg  12  54\n                                          \n               Accuracy : 0.7576          \n                 95% CI : (0.6611, 0.8381)\n    No Information Rate : 0.6667          \n    P-Value [Acc > NIR] : 0.0325          \n                                          \n                  Kappa : 0.4545          \n                                          \n Mcnemar's Test P-Value : 1.0000          \n                                          \n            Sensitivity : 0.6364          \n            Specificity : 0.8182          \n         Pos Pred Value : 0.6364          \n         Neg Pred Value : 0.8182          \n             Prevalence : 0.3333          \n         Detection Rate : 0.2121          \n   Detection Prevalence : 0.3333          \n      Balanced Accuracy : 0.7273          \n                                          \n       'Positive' Class : pos             \n                                          \n```\n:::\n:::\n\n\n\nBinaire logistische regressie is nog steeds een enorm populair ML-algoritme (voor binaire classificatie) in het bèta/technische onderzoeksdomein. Het is nog steeds zeer eenvoudig te trainen en te interpreteren, in vergelijking met veel complexere modellen.\n\n\n### Referenties\nNewman, C. B. D. & Merz, C. (1998). *UCI Repository of machine learning databases, Technical report*, University of California, Irvine, Dept. of Information and Computer Sciences.\n\nShrikant I. Bangdiwala (2018). Regression: binary logistic, *International Journal of Injury Control and Safety Promotion*, DOI: 10.1080/17457300.2018.1486503\n\n",
    "supporting": [
      "classificeren-met-tidymodels_files\\figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}