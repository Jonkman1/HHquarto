---
title: "Machine Learning Workflow"
description: |
     Deze blog is een inleiding op de workflow van Machine Learning.
author: "Harrie Jonkman en Mr.X"
date: "2022-03-25"
categories: [analyse]
image: "Screenshot.png"
---


# INTRODUCTION

`Tidymodels` is the relatively new package for machine learning with `R`. It is the successor to the `caret` package which is used during the *Introduction to Data Science*-course of the Harvard University (Kuhn & Johnson, 2013; Irizarry, 2020). `Tidymodels` is a collection of modeling packages that, like the `tidyverse`, has consistent API and are designed to work together specifically to support predictive analytics and machine learning. I followed and looked at different books (Kuhn & Silge, 2021; Kuhn en Johnson, 2019) blogs (Lendway, 2020; Roamiar (2021); Ruiz (2019), Barter (2019; Seyedia (2021) and couses/video's (Lewis, 2020; Silge, 2021; Silge 2020). I tried to learn this new system and wrote different blogs in Dutch on this[here](http://www.harriejonkman.nl/HarriesHoekje/).    

`Tidymodels` is a grammar for modeling that makes things a lot easier and provides a unified modeling and analysis interface to seamlessly access several model varities in R. `tidymodels` is a meta-package that installs and load the core packages listed below that you need for modeling and machine learning;   
- `recipes` is tidy interface for to data pre-processing tools for feature/variables engineering;    
- `rsample` provides infrastucture for efficient data splitting and resampling;   
- `parsnip` is a tidy, unified interface to models that can be used to try a range of models without getting bagged down in the syntactical minutae of the underlying packages;   
- `tune` helps you optimize the hyperparameters of your model and chose pre-processing steps;   
- `yardstick` measures the effectiveness of models during performance metrics;   
- `workflow` bundles your pre-processing modeling and post-processing together;   
- `dials` creates and manages tuning parameters and parameters grids;   
- `brooms` convert the information in common statistical R objects into user-friendly predictable formats.   

This year (2021) I learned working with `tidymodels`. I tried to finish the Capstone course with the use of this metapackage. I will show you the different steps in the working proces. 

Let us first open the packages used in this article (`tidymodels`, but also `tidyverse`, `finalfit`, `caret`, `rpart` and `randomforest`):


```{r, include=FALSE}
# ensure pacman is installed
if(!require("pacman")) installed.packages("pacman")

# install packages from CRAN 
############################
pacman::p_load(
  
tinytex,
tidyverse,
finalfit,
tidymodels,
corrplot,
caret,
rpart, 
ranger,
vip,
randomForest)

```


# PROBLEM DEFINITION

Data mining approaches are used in this article to predict human wine taste preferences that are based on easily available analytical tests at certification steps. A data set on red wine from Portugal is used here to research quality of the wine and different predictors for the quality (Cortez et al., 2009) Supervised machine learning supports us in this. In this world two kind of algorithms are often used. One is called regression (see also Attalides, 2020) and the other is called classification (not used here). 

In this study we use regression for predicting quality of wine based on several predictors.The wine data used here contains the following eleven independent variables (predictors, I1-I11) and one dependent variable (outcome, D1)

Independent variables: (symbol I)
- I1 *Fixed acidity* (g(tartaric acid/dm3)
- I2 *Volatile acidity* (g(acetic acid)/dm3)
- I3 *Citric acid* (g/dm3)
- I4 *Residual sugar* (g/dm3)
- I5 *Chlorides* (g(sodium chloride)/dm3)
- I6 *Free sulfar dioxide* (mg/dm3)
- I7 *Total sulfar dioxide* (mg/dm3)
- I8 *Density* (g/cm3)
- I9 *pH*
- I10 *Sulphates* (g(potassium sulphate)/dm3)
- I11 *Alcohol* (vol%)

Dependent variable: (symbol D)
- D1 *Quality*


# DATA LOADING, PREPROCESSING, EXPLORING

Let us load the data set (`wine.rds`) first.

```{r, include=FALSE}
wf<-readRDS("wine.rds")
```

Then, we look at the column names. 

```{r, include=FALSE}
colnames(wf)
```

And defined them on a consistent way.

```{r, include=FALSE}
colnames(wf) <- wf %>% 
  colnames() %>% str_replace_all(pattern = " ", replacement = "_")
colnames(wf)
```

Let us make an overview and summary now of this data frame.

```{r}
glimpse(wf)
summary(wf)
```

We have twelve variables inside this data set which are all continuous variables.

At this moment we want to know also something about the missings?

```{r, include=FALSE}
missing_glimpse(wf)
```

We have eight missings (three on volatile.acidity and five on alcohol). We remove any missing values and kept 1591 cases. Let us show it here.

```{r }
wf <- na.omit(wf)

missing_glimpse(wf)
```

Now we have wrangeled and preprocessed the data, we can explore them. Let us first vizualise correlations within the data-set. For this you need the package `corrplot`.

```{r}
wf %>% cor() %>% 
  corrplot.mixed(upper = "circle",
                 tl.cex = 1,
                 tl.pos = 'lt',
                 number.cex = 0.75)
```


## SPLITTING THE DATA

Now we understand the data we have to split the data into: a) Train set, b) Test set. Here we work on the last pre-model analysis. All functions below come from the `rsample` package, which is part of `tidymodels`. First we set the seed to fix the randomization and to make reproducabiltiy possible. We use 80% of the dataset for the trainingset. For a big dataset as this wine-data set with 1591 observations, 80:20-splitting works well. We split it and than make a training- and test-dataset.

```{r, include=FALSE}
set.seed(12345) 

data_split <- initial_split(wf, prop = 0.8) 

train_data <- training(data_split)

test_data  <- testing(data_split)

```


# MODELING AND DATA ANALYSIS 

Now we will compare different models with each other and want to know which one works the best for this data set with this dependent and these independent variables. This part of machine learning is called **supervised learning** of which the basic goal is to find a function that accurately describes how different measured explanatory variables can be combined to make a prediction about the target variable. We start with **linear modelling**. Regression models can help us quantify the magnitude and direction of relationships among variables.

## 1. Linear modelling
For the outcome or target variable `quality`, we first research some different linear regression models and choose the best one based on indices. For these tasks, we store each formula in a different R object.

We have to define the data: 
- The target variable. `quality` is the target variable and it is numeric
- The features of the model (predictors) are the other (independent) variables here and they are numeric variables also.

Futhermore, we design a simple formula to predict the target variable. In this formula (f1) all the available 11 predictors are used.

```{r}
formula <- formula(quality ~ fixed_acidity + volatile_acidity + citric_acid + 
                   residual_sugar + chlorides + free_sulfur_dioxide + 
                   total_sulfur_dioxide + density + pH + sulphates + alcohol)
```


Let us fit a linear regression model to the data. What we do:
- First, we created an object that will store the model fit.    
- Then, we specify the model.   
- Then, We specify also that we work with regression because of the continue target variable (`quality`).
- Then, we specify also the `lm` package to train the model.
- And we finish in this chunck by adding the formula and the training data to fit the model.

Let us see how this workflow works.

```{r}
lm_fit <- 
  linear_reg() %>% 
  set_mode("regression") %>% 
  set_engine("lm") %>% 
  fit(formula, data = train_data) 
```

We present the results on different ways 

```{r, include=FALSE}
print(lm_fit$fit)
```

But this is probably the best and clearest way to show the results.

```{r}
summary(lm_fit$fit)
```

We can also visualize the fit summary by using the `broom` package which is inside `tidymodels`.

```{r}
tidy(lm_fit$fit) %>% mutate_if(is.numeric, round, 3)
```


## 2. Decision tree
After we worked with linear regression, it is possible to work with other models which maybe give us better results for predicting the outcome. Let us first look at decision tree modeling. A decision tree is tree-like flowchart that assigns labels to individual observations. It splits it into homogeneous subsets, which share the same class labels. For this you need decision tree package and for this you have to install and open the library of `rpart`. We see similar steps here in the machine learning workflow. 
Once again, the workflow:
- define an object `dt_fit`;   
- tell that we work with decision tree;   
- set the mode on regression;   
- set the engine on `rpart`;   
- fit the formula on the training data-set.   

```{r, include=FALSE}

dt_fit <- 
  decision_tree() %>% 
  set_mode("regression") %>%
  set_engine("rpart") %>% 
  fit(formula, data = train_data)
```

Print the results

```{r}
print(dt_fit$fit)
```

As a sidestep, we can visualize this, but than we have to install and open the `visNetwork` and `sparkline` packages. Then we see this.

```{r}
library(visNetwork)
library(sparkline)
visTree(dt_fit$fit)
```

## 3. Random forest
A third model we use here is RandomForest. RandomForest is a natural extension of DecisionTree. A RandomForest is a collection of Deciontrees that are aggregated by majority rule, and is in essence a collection 'bootstrapped' decision trees. You need to install `randomForest` package and open the library `randomForest`. 
And also here, once again the same steps:
- define object `rf_fit`;    
- tell we want to use randomforest;    
- set the mode again on regression;      
- set the engine here on randomForest;    
- fit the model on the training_set.   

```{r, include=FALSE}
rf_fit <- 
  rand_forest() %>% 
  set_mode("regression") %>%
  set_engine("randomForest") %>% 
  fit(formula, data = train_data)
```

Print these results (not shown here).

```{r}
print(rf_fit$fit)
```


# EVALUATION AND PREDICTION

Now we have three objects of the three models we ran and which we have to compare and evaluate. We do this on the test-set. We compare the three models (`lm_fit`, `dt_fit` and `rf_fit`) on the Men Square Score (MSE) score. We need to find a model algorithm that produces predictors for the outcome (`quality`) that minimizes the MSE-score. So, the lower the mse-score of the model, the better.


## 1. Accuracy of the lm-model

Let us first look at the accuracy of the linear-model.

```{r, include=FALSE}
lm_pred <- test_data %>% 
  bind_cols(predict(object = lm_fit, new_data = test_data))
```

Now we see a new column, `.pred`, with a predicted scores for each row. 

```{r, include=FALSE}
View(lm_pred)

```

```{r,include=FALSE}
lm_pred <- test_data %>% 
  bind_cols(predict(object = lm_fit, new_data = test_data)) %>% 
  mutate(pred = round(.pred, 0))

```


```{r, include=FALSE}
lm_mse <- lm_pred %>% 
  summarise(type = "lm",
            MSE = round(mean((pred - quality)^2), 4))
```

It gives here the following mse-score for linear modeling, which we show here.

```{r}
head(lm_mse)
```


## 2. Accuracy of the Decision Tree Model
Then we look at the accuracy of the DecisionTree Model.

```{r, include=FALSE}
dt_pred <- test_data %>% 
  bind_cols(predict(object = dt_fit, new_data = test_data)) %>% 
  rename(pred = .pred) %>% 
  mutate(pred = round(pred, 0))
```

```{r, include=FALSE}
dt_mse <- dt_pred %>% 
  summarise(type = "dt",
            MSE = round(mean((pred - quality)^2), 4))
```

The decision model gives the following mse-score.

```{r}
head(dt_mse)
```


## 3. Accuracy of the Random Forest Model
And then ofcourse we also have to look at the accuracy of the RandomForest-model. 

```{r, include=FALSE}
rf_pred <- test_data %>% 
  bind_cols(predict(object = rf_fit, new_data = test_data)) %>% 
  rename(pred = .pred) %>% 
  mutate(pred = round(pred, 0))
```

```{r, include=FALSE}
rf_mse <- rf_pred %>% 
  summarise(type = "rf",
            MSE = round(mean((pred - quality)^2), 4))
```

The Random Forest Model gives us the following mse-score:

```{r}
head(rf_mse)
```


## All results together

Let us put all the results together and compare them with each other.

```{r, include=FALSE}
res <- bind_rows(lm_mse, dt_mse, rf_mse)
```

Let us show these results together.

```{r}
head(res)
```
Altogether the prediction scores don't look very well, but we know that RandomForest is the best model for prediction.

```{r}
metrics(rf_pred, quality, pred)
```

Now we choosed the random forest model, we can look at the importance of the ten independent variables and compare them with each other. We see that alcohol is the most import predictor for quality followed by sulphates ad volatile_acidity. Residul-sugar, pH and fixed_acidity are the lowest important predictors for quality of wine.

```{r}
library(vip)
vip(rf_fit)
```

Let us look at which percentage of the test sample are wrongly predicted.

```{r, include=F}
ifelse(rf_pred$quality==rf_pred$pred, "Yes", "No")
```

$105/307*100= 34,2%$ is not correctly predicted. So $65,8%$ is predicted correctly with this model. We choose the random_forest model as the best opportunity here. Let us look at it once again.

```{r}
head(rf_pred)
```


# CONCLUSION

In this simple scenario, we were interested in seeing how the model performs on the testing data that were left out. The code fitted the model to the training data and apply it to the testing data. There are other ways we could have done this, but the way we do it here will be useful when we start using more complex models where we need to tune model parameters. Root Mean Square Error (RMSE) is a standard way to measure the error of a model in predicting quantitative data. RMSE is a good measure to use if we want to estimate the standard deviation of a typical observed value from our modelâ€™s prediction, R-squared is a statistical measure that represents the goodness of fit of a regression model. The ideal value for r-square is 1. The closer the value of r-square to 1, the better is the model fitted. In Machine Learning, MAE is a model evaluation metric often used with regression models. After the model is fitted and applied, we collected the performance metrics and display them and show the predictions from the testing data.  34,2% is predicted wrong, which is at the end maybe a bit disappointing after all the work. But we know what the best model is for this data-set.    
This work has some **strengths** We found a uniform and consistent way to compare models with each and to choose the best one out of them. One of the big advantages of the random forest model (which is choosen here) is the versality and flexibility. It can be used for both regression and classification problems. But this work has also some **limitations**. Random forest is good for predictions and regression, so this could be used by the researcher for interpretation here. But for of modelling is relatively new for this researcher (instead of linear regression for example) so he found himself restricted here at the end. A limitation of random forest is also that this algorithm is fast to train, but quit slow to create predictions once they are trained: a more accurate prediction needs more trees, which results in a slower model. And a last limitation which we have to mention here is, that we used only three models and maybe other models were better for these data. 

Lesson learned is that we found a consitent workflow for analyzing data as presented here on quality of wine. It is a very good starting point for further research. The next step would be now to work on increasing the predictive power of the model and start with tuning on the hyperparameters. 


# References

Attalides, N. (2020). [Introduction to machine learning. Barcelona. Presentation](https://www.barcelonar.org/workshops/BarcelonaR_Introduction_to_Machine_Learning.pdf) 

Barter, R.(2020). [Tidymodels: tidy machine learning in R](http://www.rebeccabarter.com/blog/2020-03-25_machine_learning/) 

Baumer, B. Kaplan, D.T., Horton, N.J. (2017). *Modern data science with R*. CRCPress: Boca Raton.

Boehmke, B. & Greenwell, B. (2020). *Hands on machine learning with R*. [Bookdown version](https://bradleyboehmke.github.io/HOML)

Cortez, P., Cerdeira, A., Almeida, F., Matos, T. & Reis, J. (2009). Modeling wine prefernces by data mining from physicochemical properties. *Decision Support Systems, 47*, 547-533. 

Hartie, T., Tibskirani, R. & Friedmann, J. (2009). *The elements of statistical learning. Data mining, inference and prediction*. 2nd edition. Springer: New York.

Irizarry, R.A. (2020). *Introduction to data science. Data analysis and prediction algorithms with R*. CRC Press: Boca Raton.

James, S., Witten, D., Hastie, T.. & Tibskirani, R. (2013). *An introduction to statistical learning with application in R*. 

Jonkman, H. (2019-2021). [Harrie's hoekje, his website with different blogs on machine learning in Dutch](http://www.harriejonkman.nl/HarriesHoekje/) 

Kuhn, M. 7 Johnson, K. (2013). *Applied predictive modeling*. Springer: New York.

Kuhn, M. & Johnson, K. (2019). [Feature engineering and selection: A practical approach for predictive models](www.feat.engineering)

Kuhn, M. & Silge, J. (2021). Tydy modeling with R. [Bookdown version](https://www.tmwr.org/)

Lendway, L. (2020). 2020_north-tidymodels.[Introduction on github](https://github.com/llendway/2020_north_tidymodels)

Lewis, J.E. (2020). [Coding machine learning models](https://www.youtube.com/watch?v=WlL44_is4TU)

Raoniar, R. (2021). Modeling binary logistic regression using tidymodels library in R (Part 1). [Towards data science](https://towardsdatascience.com/modelling-binary-logistic-regression-using-tidymodels-library-in-r-part-1-c1bdce0ac055)

Ruiz, E. (2019). [A gentle introduction to tidymodels](https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/)

Seyedian, A. (2021). [Medical cost personal datasets. Insurance forcast by using linear regression](https://www.r-bloggers.com/2021/02/using-tidymodels-to-predict-health-insurance-cost/)

Silge, J. (2020). [Get started with tidymodels and #TidyTuesdag Palmer penguins](https://juliasilge.com/blog/palmer-penguins/)

Silge, J. (2021). [Supervised machine learning case studies in R](https://supervised-ml-course)

Tidymodels. [Tidymodels website](https://www.tidymodels.org/)



