{
  "hash": "ec0f32e673b5d3a60c4638111eb46d49",
  "result": {
    "markdown": "---\ntitle: \"Werken met Tidymodels, een suite voor machine learning\"\ndescription: |\n    `Tidymodels` is het suite-pakket van Posit om met machinelearning te werken. Op de website staan vijf handleidingen die voor deze post wat bewerkt zijn en die de verschillende aspecten van het pakket laten zien. Het is een introductie, het vertelt iets over de belangrijkste onderdelen en er wordt een uitgebreide case-studie gepresenteerd.\nauthor: \"Max Kuhn en Julia Silge, bewerkt door HarrieJonkman\"\ndate: \"2023-01-11\"\ncategories: [modelleren]\nimage: \"Screenshot1.PNG\"\n---\n\n\n\n# Introductie\n\n`Tidymodels` is een nieuwe versie van Max Kuhns pakket `CARET` en kan voor verschillende machine learning taken worden gebruikt. Het is sterk geïnspireerd door `Tidyverse`. Ook `Tidymodels` is een suite van verschillende pakketten, van voorbereiding tot en met evaluatie en dat het mogelijk maakt om het uitvoeren van analyses steeds op een vergelijkbare manier uit te voeren. Over dit pakket is een zeer duidelijke website gemaakt met uitleg [website](https://www.tidymodels.org). Tegelijkertijd is er het [boek](https://www.tmwr.org). Hieronder zie je een bewerkte versie van de vijf handleidingen die op de website zijn te vinden.\n\n# Handleiding 1: Overall\n\nMet de eerste handleiding ([see](https://www.tidymodels.org/start/models/) krijg je een idee hoe `tidymodels` werkt. Hierin zet je enkele belangrijke stappen: je opent de data, specificeert en traint het model, gebruikt daarbij verschillende `engines` (technieken) en je leert te begrijpen hoe het allemaal werkt. In deze handleiding staat het [`parsnip`-pakket](https://parsnip.tidymodels.org/) centraal.\n\nEerst moet je, zoals altijd, enkele pakketten openen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Het basispakket\nlibrary(tidymodels)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching packages ────────────────────────────────────── tidymodels 1.0.0 ──\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n✔ broom        1.0.1      ✔ recipes      1.0.1 \n✔ dials        1.0.0      ✔ rsample      1.1.0 \n✔ dplyr        1.0.10     ✔ tibble       3.1.8 \n✔ ggplot2      3.4.0      ✔ tidyr        1.2.1 \n✔ infer        1.0.3      ✔ tune         1.0.0 \n✔ modeldata    1.0.1      ✔ workflows    1.1.0 \n✔ parsnip      1.0.1      ✔ workflowsets 1.0.0 \n✔ purrr        1.0.0      ✔ yardstick    1.1.0 \n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ purrr::discard() masks scales::discard()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ recipes::step()  masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n```\n:::\n\n```{.r .cell-code}\n## Enkele ondersteunende pakketten \nlibrary(readr)       # voor importeren van data\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'readr'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:yardstick':\n\n    spec\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:scales':\n\n    col_factor\n```\n:::\n\n```{.r .cell-code}\nlibrary(broom.mixed) # om bayesiaanse modellen om te zetten naar tidy tibbles\nlibrary(dotwhisker)  # voor visualiseren van regressieresultaten\n```\n:::\n\n\n## De dataset\n\nIn deze handleiding wordt met data van zeeëgels gewerkt. [Hier](https://link.springer.com/article/10.1007/BF00349318) vind je het artikel over voedingsregimes dat hieronder wordt uitgewerkt\n\nEerst maar eens die data inlezen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nurchins <-\n# Data werden verzameld voor de handleiding\n# zie https://www.flutterbys.com.au/stats/tut/tut7.5a.html\nread_csv(\"https://tidymodels.org/start/models/urchins.csv\") %>%\n# Verander de namen om ze iets minder uitgebreid te laten zijn\nsetNames(c(\"food_regime\", \"initial_volume\", \"width\")) %>%\n# Factoren zijn handig bij modeleren, daarom een kolumn omgezet\nmutate(food_regime = factor(food_regime, levels = c(\"Initial\", \"Low\", \"High\")))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 72 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): TREAT\ndbl (2): IV, SUTW\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n\nLaten we de data vervolgens eens bekijken, met 72 rijen (zeeëgels) en drie variabelen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglimpse(urchins)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 72\nColumns: 3\n$ food_regime    <fct> Initial, Initial, Initial, Initial, Initial, Initial, I…\n$ initial_volume <dbl> 3.5, 5.0, 8.0, 10.0, 13.0, 13.0, 15.0, 15.0, 16.0, 17.0…\n$ width          <dbl> 0.010, 0.020, 0.061, 0.051, 0.041, 0.061, 0.041, 0.071,…\n```\n:::\n:::\n\n\nHet is goed om de data dan ook eens te visualiseren.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n ggplot(urchins,\n               aes(x = initial_volume,\n                   y = width,\n                   group = food_regime,\n                   col = food_regime)) +\n                geom_point() +\n                geom_smooth(method = lm, se = FALSE) +\n                scale_color_viridis_d(option = \"plasma\", end = .7)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n## Bouwen en fitten van een model\n\nEen standaard twee-weg analyse van variantie (ANOVA) is zinvol voor deze dataset omdat deze zowel een continue als een categorische voorspeller bevat.\n\nIn dit geval draaien we een lineaire regressie.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_mod <-\n        linear_reg() %>%\n        set_engine(\"lm\")\n##  Train/fit/schatten van model \nlm_fit <-\n                lm_mod %>%\n                fit(width ~ initial_volume * food_regime, data = urchins)\n## tidy uitprinten\ntidy(lm_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 5\n  term                            estimate std.error statistic  p.value\n  <chr>                              <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)                     0.0331    0.00962      3.44  0.00100 \n2 initial_volume                  0.00155   0.000398     3.91  0.000222\n3 food_regimeLow                  0.0198    0.0130       1.52  0.133   \n4 food_regimeHigh                 0.0214    0.0145       1.47  0.145   \n5 initial_volume:food_regimeLow  -0.00126   0.000510    -2.47  0.0162  \n6 initial_volume:food_regimeHigh  0.000525  0.000702     0.748 0.457   \n```\n:::\n\n```{.r .cell-code}\n## resultaten plotten\n        tidy(lm_fit) %>%\n                dwplot(dot_args = list(size = 2, color = \"black\"),\n                       whisker_args = list(color = \"black\"),\n                       vline = geom_vline(xintercept = 0, colour = \"grey50\", linetype = 2))\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n## Een model gebruiken om te voorspellen\n\nHet model hebben we gedefinieerd. Stel dat we vervolgens een voorspelling willen maken voor egels met een volume van 20ml. Zet deze punten erin.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n new_points <- expand.grid(initial_volume = 20,\n                          food_regime = c(\"Initial\", \"Low\", \"High\"))\n```\n:::\n\n\nFit dan het model met deze nieuwe datapunten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean_pred <- predict(lm_fit, new_data = new_points)\nmean_pred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 1\n   .pred\n   <dbl>\n1 0.0642\n2 0.0588\n3 0.0961\n```\n:::\n:::\n\n\nLaat dan ook de betrouwbaarheidsintervallen hiervoor zien.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconf_int_pred <- predict(lm_fit,\n                                 new_data = new_points,\n                                 type = \"conf_int\")\n```\n:::\n\n\nCombineer de informatie.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_data <-\n                new_points %>%\n                bind_cols(mean_pred) %>%\n                bind_cols(conf_int_pred)\n```\n:::\n\n\nEn plot dan de resultaten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n ggplot(plot_data, aes(x = food_regime)) +\n                geom_point(aes(y = .pred)) +\n                geom_errorbar(aes(ymin = .pred_lower,\n                                  ymax = .pred_upper),\n                              width = .2) +\n                labs(y = \"urchin size\")\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n## Model met een andere `engine`.\n\nLaten we nu niet lineaire regressie op een standaardmanier uitvoeren. Stel dat we het nu Bayesiaans willen doen. In dat geval moet je eerst de prior-distributie vastzetten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n prior_dist <- rstanarm::student_t(df = 1)\n        set.seed(123)\n```\n:::\n\n\nDan definiëren we het model opnieuw.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n bayes_mod <-\n                linear_reg() %>%\n                set_engine(\"stan\",\n                           prior_intercept = prior_dist,\n                           prior = prior_dist)\n```\n:::\n\n\nVervolgens trainen we het nieuwe model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n bayes_fit <-\n                bayes_mod %>%\n                fit(width ~ initial_volume * food_regime, data = urchins)\n```\n:::\n\n\nPrint de gegevens van het model vervolgens uit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  print(bayes_fit, digits = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nparsnip model object\n\nstan_glm\n family:       gaussian [identity]\n formula:      width ~ initial_volume * food_regime\n observations: 72\n predictors:   6\n------\n                               Median   MAD_SD  \n(Intercept)                     0.03338  0.00947\ninitial_volume                  0.00155  0.00039\nfood_regimeLow                  0.01936  0.01348\nfood_regimeHigh                 0.02073  0.01395\ninitial_volume:food_regimeLow  -0.00125  0.00052\ninitial_volume:food_regimeHigh  0.00055  0.00069\n\nAuxiliary parameter(s):\n      Median  MAD_SD \nsigma 0.02143 0.00180\n\n------\n* For help interpreting the printed output see ?print.stanreg\n* For info on the priors used see ?prior_summary.stanreg\n```\n:::\n:::\n\n\n# Handleiding 2: Voorbereiding\n\nIn de tweede handleiding staan met name voorbereidende activiteiten centraal, activiteiten die je moet uitvoeren voordat je gaat modelleren. Hierbij gaat het bijvoorbeeld om het omzetten van variabelen zodat ze beter werken bij modelleren, variabelen naar andere schalen omzetten, hele groepen variabelen omzetten of om nadrukken te leggen op bepaalde aspecten van variabelen. Het gaat vooral om het pakket [recipes](https://www.tidymodels.org/start/recipes/).\n\nNu deze pakketten laden.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(nycflights13)    # voor vluchtdata\nlibrary(skimr)           # voor samenvattingen van variabelen\n```\n:::\n\n\n## De data\n\nHet gaat hier om New York City vluchtdata.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set seed om ervoor te zorgen dat herhalingen zelfde resultaten geven ----\nset.seed(123)\n## Laden van data ----\ndata(flights)\n## Bekijken van data ----\nskimr::skim(flights)\n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |        |\n|:------------------------|:-------|\n|Name                     |flights |\n|Number of rows           |336776  |\n|Number of columns        |19      |\n|_______________________  |        |\n|Column type frequency:   |        |\n|character                |4       |\n|numeric                  |14      |\n|POSIXct                  |1       |\n|________________________ |        |\n|Group variables          |None    |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|carrier       |         0|          1.00|   2|   2|     0|       16|          0|\n|tailnum       |      2512|          0.99|   5|   6|     0|     4043|          0|\n|origin        |         0|          1.00|   3|   3|     0|        3|          0|\n|dest          |         0|          1.00|   3|   3|     0|      105|          0|\n\n\n**Variable type: numeric**\n\n|skim_variable  | n_missing| complete_rate|    mean|      sd|   p0|  p25|  p50|  p75| p100|hist  |\n|:--------------|---------:|-------------:|-------:|-------:|----:|----:|----:|----:|----:|:-----|\n|year           |         0|          1.00| 2013.00|    0.00| 2013| 2013| 2013| 2013| 2013|▁▁▇▁▁ |\n|month          |         0|          1.00|    6.55|    3.41|    1|    4|    7|   10|   12|▇▆▆▆▇ |\n|day            |         0|          1.00|   15.71|    8.77|    1|    8|   16|   23|   31|▇▇▇▇▆ |\n|dep_time       |      8255|          0.98| 1349.11|  488.28|    1|  907| 1401| 1744| 2400|▁▇▆▇▃ |\n|sched_dep_time |         0|          1.00| 1344.25|  467.34|  106|  906| 1359| 1729| 2359|▁▇▇▇▃ |\n|dep_delay      |      8255|          0.98|   12.64|   40.21|  -43|   -5|   -2|   11| 1301|▇▁▁▁▁ |\n|arr_time       |      8713|          0.97| 1502.05|  533.26|    1| 1104| 1535| 1940| 2400|▁▃▇▇▇ |\n|sched_arr_time |         0|          1.00| 1536.38|  497.46|    1| 1124| 1556| 1945| 2359|▁▃▇▇▇ |\n|arr_delay      |      9430|          0.97|    6.90|   44.63|  -86|  -17|   -5|   14| 1272|▇▁▁▁▁ |\n|flight         |         0|          1.00| 1971.92| 1632.47|    1|  553| 1496| 3465| 8500|▇▃▃▁▁ |\n|air_time       |      9430|          0.97|  150.69|   93.69|   20|   82|  129|  192|  695|▇▂▂▁▁ |\n|distance       |         0|          1.00| 1039.91|  733.23|   17|  502|  872| 1389| 4983|▇▃▂▁▁ |\n|hour           |         0|          1.00|   13.18|    4.66|    1|    9|   13|   17|   23|▁▇▇▇▅ |\n|minute         |         0|          1.00|   26.23|   19.30|    0|    8|   29|   44|   59|▇▃▆▃▅ |\n\n\n**Variable type: POSIXct**\n\n|skim_variable | n_missing| complete_rate|min                 |max                 |median              | n_unique|\n|:-------------|---------:|-------------:|:-------------------|:-------------------|:-------------------|--------:|\n|time_hour     |         0|             1|2013-01-01 05:00:00 |2013-12-31 23:00:00 |2013-07-03 10:00:00 |     6936|\n:::\n:::\n\n\nLaten we enkele veranderingen in de dataset aanbrengen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflight_data <-\n                flights %>%\n                mutate(\n# Converteer de 'arrival delay'-variabele in een factorvariabele\n                  arr_delay = ifelse(arr_delay >= 30, \"late\", \"on_time\"),\n                  arr_delay = factor(arr_delay),\n# We zullen de datum en niet de tijd gebruiken\n                  date = as.Date(time_hour)\n                ) %>%\n# Includeer ook de weersdata\ninner_join(weather, by = c(\"origin\", \"time_hour\")) %>%\n# We gebruiken alleen specifieke kolommen\nselect(dep_time, flight, origin, dest, air_time, distance,\n                       carrier, date, arr_delay, time_hour) %>%\n# Missende data halen we eruit\nna.omit() %>%\n# Voor het draaien van modellen, is het beter om kwalitatieve data te hebbebn\n# zet deze om in factoren (ipv karakter strings)\nmutate_if(is.character, as.factor)\n```\n:::\n\n\nWe zien dat 16% meer dan een half uur vertraging heeft.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflight_data %>% \n  count(arr_delay) %>% \n  mutate(prop = n/sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  arr_delay      n  prop\n  <fct>      <int> <dbl>\n1 late       52540 0.161\n2 on_time   273279 0.839\n```\n:::\n:::\n\n\nLaten we de veranderingen eens bekijken. We zien bv dat de variabele `arr-delay` een factor variabele geworden is. Dat is voor het trainen van een logistisch regressiemodel van belang. `flight` is een numerieke variabele en `time-hour` is een dttm variabele. Die gebruiken we niet in de training maar wel als eventuele controlevariabelen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n glimpse(flight_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 325,819\nColumns: 10\n$ dep_time  <int> 517, 533, 542, 544, 554, 554, 555, 557, 557, 558, 558, 558, …\n$ flight    <int> 1545, 1714, 1141, 725, 461, 1696, 507, 5708, 79, 301, 49, 71…\n$ origin    <fct> EWR, LGA, JFK, JFK, LGA, EWR, EWR, LGA, JFK, LGA, JFK, JFK, …\n$ dest      <fct> IAH, IAH, MIA, BQN, ATL, ORD, FLL, IAD, MCO, ORD, PBI, TPA, …\n$ air_time  <dbl> 227, 227, 160, 183, 116, 150, 158, 53, 140, 138, 149, 158, 3…\n$ distance  <dbl> 1400, 1416, 1089, 1576, 762, 719, 1065, 229, 944, 733, 1028,…\n$ carrier   <fct> UA, UA, AA, B6, DL, UA, B6, EV, B6, AA, B6, B6, UA, UA, AA, …\n$ date      <date> 2013-01-01, 2013-01-01, 2013-01-01, 2013-01-01, 2013-01-01,…\n$ arr_delay <fct> on_time, on_time, late, on_time, on_time, on_time, on_time, …\n$ time_hour <dttm> 2013-01-01 05:00:00, 2013-01-01 05:00:00, 2013-01-01 05:00:…\n```\n:::\n:::\n\n\nEr zijn 104 vluchtbestemmingen en 16 verschillende maatschappijen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflight_data %>% \n  skimr::skim(dest, carrier) \n```\n\n::: {.cell-output-display}\nTable: Data summary\n\n|                         |           |\n|:------------------------|:----------|\n|Name                     |Piped data |\n|Number of rows           |325819     |\n|Number of columns        |10         |\n|_______________________  |           |\n|Column type frequency:   |           |\n|factor                   |2          |\n|________________________ |           |\n|Group variables          |None       |\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                                     |\n|:-------------|---------:|-------------:|:-------|--------:|:----------------------------------------------|\n|dest          |         0|             1|FALSE   |      104|ATL: 16771, ORD: 16507, LAX: 15942, BOS: 14948 |\n|carrier       |         0|             1|FALSE   |       16|UA: 57489, B6: 53715, EV: 50868, DL: 47465     |\n:::\n:::\n\n\n## Data splitten\n\nVervolgens splitsenen we de dataset in training- en testdata. We splitten het en dan maken we twee datasets.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(555)\n## Splitsen ----\ndata_split <- initial_split(flight_data, prop = 3/4)\n## Training & Testing ----\ntrain_data <- training(data_split)\ntest_data  <- testing(data_split)\n```\n:::\n\n\nDefinieer het model en geef twee variabelen een nieuwe rol (ID). Deze kun je later gebruiken om te zien als iets niet helemaal goed gegaan is bij het voorspellen. Laat uiteindelijk zien hoe de dataset eruit ziet.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_rec <-\n        recipe(arr_delay ~ ., data = train_data)\n        \nflights_rec <-\n                recipe(arr_delay ~ ., data = train_data) %>%\n                update_role(flight, time_hour, new_role = \"ID\")\n\nsummary(flights_rec)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 × 4\n   variable  type    role      source  \n   <chr>     <chr>   <chr>     <chr>   \n 1 dep_time  numeric predictor original\n 2 flight    numeric ID        original\n 3 origin    nominal predictor original\n 4 dest      nominal predictor original\n 5 air_time  numeric predictor original\n 6 distance  numeric predictor original\n 7 carrier   nominal predictor original\n 8 date      date    predictor original\n 9 time_hour date    ID        original\n10 arr_delay nominal outcome   original\n```\n:::\n:::\n\n\nWe voegen nog enkele handelingen toe met `recipe`. Je kunt verschillende zaken tegelijk uitvoeren mbt verschillende variabelen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_rec <-\n        recipe(arr_delay ~ ., data = train_data) %>%\n        update_role(flight, time_hour, new_role = \"ID\") %>%\n        step_date(date, features = c(\"dow\", \"month\")) %>%\n        step_holiday(date, holidays = timeDate::listHolidays(\"US\")) %>%\n        step_rm(date) %>%\n        step_dummy(all_nominal(), -all_outcomes()) %>%\n        step_zv(all_predictors())\n```\n:::\n\n\n## Model fitten\n\nWe specificeren het model als logistische regressie met de glm als `engine` en specificeren de workflow.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_mod <-\n          logistic_reg() %>%\n          set_engine(\"glm\")\n## Specificeren workflow ----\nflights_wflow <-\n          workflow() %>%\n          add_model(lr_mod) %>%\n          add_recipe(flights_rec)\nflights_wflow\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: logistic_reg()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n5 Recipe Steps\n\n• step_date()\n• step_holiday()\n• step_rm()\n• step_dummy()\n• step_zv()\n\n── Model ───────────────────────────────────────────────────────────────────────\nLogistic Regression Model Specification (classification)\n\nComputational engine: glm \n```\n:::\n:::\n\n\nVervolgens fitten we het model en kijken naar de resultaten.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n flights_fit <-\n                flights_wflow %>%\n                fit(data = train_data)\n## Halen resultaten eruit\n flights_fit %>%\n                pull_workflow_fit() %>%\n                tidy()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `pull_workflow_fit()` was deprecated in workflows 0.2.3.\nℹ Please use `extract_fit_parsnip()` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 158 × 5\n   term                         estimate std.error statistic  p.value\n   <chr>                           <dbl>     <dbl>     <dbl>    <dbl>\n 1 (Intercept)                   5.25    2.72           1.93 5.40e- 2\n 2 dep_time                     -0.00167 0.0000141   -118.   0       \n 3 air_time                     -0.0438  0.000561     -78.0  0       \n 4 distance                      0.00615 0.00150        4.10 4.09e- 5\n 5 date_USChristmasDay           1.14    0.171          6.65 2.86e-11\n 6 date_USColumbusDay            0.627   0.169          3.72 2.03e- 4\n 7 date_USCPulaskisBirthday      0.702   0.133          5.29 1.25e- 7\n 8 date_USDecorationMemorialDay  0.363   0.117          3.11 1.86e- 3\n 9 date_USElectionDay            0.695   0.177          3.92 8.87e- 5\n10 date_USGoodFriday             1.15    0.156          7.39 1.45e-13\n# … with 148 more rows\n```\n:::\n:::\n\n\n## Voorspellen\n\nWe gebruiken de getrainde werkflow om te voorspellen. Nu zetten we deze werkflow van de trainingsset in op de testdata.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(flights_fit, test_data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 81,455 × 1\n   .pred_class\n   <fct>      \n 1 on_time    \n 2 on_time    \n 3 on_time    \n 4 on_time    \n 5 on_time    \n 6 on_time    \n 7 on_time    \n 8 on_time    \n 9 on_time    \n10 on_time    \n# … with 81,445 more rows\n```\n:::\n:::\n\n\nLaat het voorspellen van de testdata zien en geef de waarschijnlijkheid terug.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_pred <-\n                predict(flights_fit, test_data, type = \"prob\") %>%\n                bind_cols(test_data %>% select(arr_delay, time_hour, flight))\n        flights_pred\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 81,455 × 5\n   .pred_late .pred_on_time arr_delay time_hour           flight\n        <dbl>         <dbl> <fct>     <dttm>               <int>\n 1     0.0183         0.982 on_time   2013-01-01 06:00:00    461\n 2     0.0426         0.957 on_time   2013-01-01 06:00:00   5708\n 3     0.0413         0.959 on_time   2013-01-01 06:00:00     71\n 4     0.0253         0.975 on_time   2013-01-01 06:00:00    194\n 5     0.0306         0.969 on_time   2013-01-01 06:00:00   1743\n 6     0.0236         0.976 on_time   2013-01-01 06:00:00   1077\n 7     0.0119         0.988 on_time   2013-01-01 06:00:00    709\n 8     0.137          0.863 on_time   2013-01-01 06:00:00    245\n 9     0.0526         0.947 on_time   2013-01-01 06:00:00   4599\n10     0.0246         0.975 on_time   2013-01-01 06:00:00   1019\n# … with 81,445 more rows\n```\n:::\n:::\n\n\nPlot deze gegevens met name via [yardstick-pakket](https://yardstick.tidymodels.org/)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n flights_pred %>%\n                roc_curve(truth = arr_delay, .pred_late) %>%\n                autoplot()\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-28-1.png){width=672}\n:::\n:::\n\n\nHoe groot is nu de AREA onder de curve? 76,1%, redelijk.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n flights_pred %>%\n                roc_auc(truth = arr_delay, .pred_late)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.761\n```\n:::\n:::\n\n\n# Handleiding 3: Evaluatie\n\nIn de derde handleiding gaat het vooral om het evalueren van het model. We willen de performance van het model weten en dat doen we vooral met het [resampling-pakket](url:%20https://www.tidymodels.org/start/resampling/)\n\nEerst gaan we de data binnenhalen waar we in deze handleiding mee zullen werken. Het gaat om data die iets zeggen over de kwaliteit van celbeeld segementatie. Ze zitten in dit pakket.\n\nBij het vaststellen van effecten van drugs (medicijn wel of niet) wordt er vaak gekeken naar de effecten op de cellen. Dat is op de beelden te zien. Dan wordt er naar de kleur of de afmeting gekeken of naar segmentatie zoals hier.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tidymodels hebben we al actief gemaakt\n# voor de cellen data ----\nlibrary(modeldata) \n\n## Laad de data ----\ndata(cells, package = \"modeldata\")\n\n## Dit zijn de data\ncells\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,019 × 58\n   case  class angle_c…¹ area_…² avg_i…³ avg_i…⁴ avg_i…⁵ avg_i…⁶ conve…⁷ conve…⁸\n   <fct> <fct>     <dbl>   <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Test  PS       143.       185    15.7    4.95    9.55    2.21    1.12   0.920\n 2 Train PS       134.       819    31.9  207.     69.9   164.      1.26   0.797\n 3 Train WS       107.       431    28.0  116.     63.9   107.      1.05   0.935\n 4 Train PS        69.2      298    19.5  102.     28.2    31.0     1.20   0.866\n 5 Test  PS         2.89     285    24.3  112.     20.5    40.6     1.11   0.957\n 6 Test  WS        40.7      172   326.   654.    129.    347.      1.01   0.993\n 7 Test  WS       174.       177   260.   596.    124.    273.      1.01   0.984\n 8 Test  PS       180.       251    18.3    5.73   17.2     1.55    1.20   0.831\n 9 Test  WS        18.9      495    16.1   89.5    13.7    51.4     1.19   0.822\n10 Test  WS       153.       384    17.7   89.9    20.4    63.1     1.16   0.865\n# … with 2,009 more rows, 48 more variables: diff_inten_density_ch_1 <dbl>,\n#   diff_inten_density_ch_3 <dbl>, diff_inten_density_ch_4 <dbl>,\n#   entropy_inten_ch_1 <dbl>, entropy_inten_ch_3 <dbl>,\n#   entropy_inten_ch_4 <dbl>, eq_circ_diam_ch_1 <dbl>,\n#   eq_ellipse_lwr_ch_1 <dbl>, eq_ellipse_oblate_vol_ch_1 <dbl>,\n#   eq_ellipse_prolate_vol_ch_1 <dbl>, eq_sphere_area_ch_1 <dbl>,\n#   eq_sphere_vol_ch_1 <dbl>, fiber_align_2_ch_3 <dbl>, …\n```\n:::\n\n```{.r .cell-code}\n## Uitkomst variable is 'class'\n## PS = \"poorly segmented, slecht gesegementeerd\" WS = \"weekly segmented, zwak gesegementeerd\"\n        cells %>%\n                count(class) %>%\n                mutate(prop = n/sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  class     n  prop\n  <fct> <int> <dbl>\n1 PS     1300 0.644\n2 WS      719 0.356\n```\n:::\n:::\n\n\n## Data splitsen\n\nDe functie `rsample::initial_split()` neemt de oorspronkelijke gegevens en slaat de informatie op over hoe de delen moeten worden gemaakt. In de oorspronkelijke analyse maakten de auteurs hun eigen trainings-/testset en die informatie staat in de kolom \"case\". Om te demonstreren hoe we een splitsing maken, verwijderen we deze kolom voordat we onze eigen splitsing maken.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ncell_split <- rsample::initial_split(cells %>% select(-case),\n                            strata = class)\n```\n:::\n\n\nHier hebben we het strata-argument gebruikt, dat een gestratificeerde splitsing uitvoert. Dit zorgt ervoor dat, ondanks de onevenwichtigheid die we in onze klassenvariabele hebben opgemerkt, onze trainings- en testdatasets ongeveer dezelfde proporties slecht gesegmenteerde en goed gesegmenteerde cellen behouden als in de oorspronkelijke gegevens. Na de initiële splitsing leveren de functies training() en test() de eigenlijke datasets op.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncell_train <- training(cell_split)\ncell_test  <- testing(cell_split)\n\nnrow(cell_train)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1514\n```\n:::\n\n```{.r .cell-code}\nnrow(cell_train)/nrow(cells)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7498762\n```\n:::\n\n```{.r .cell-code}\n# trainingset proporties volgens class\ncell_train %>% \n  count(class) %>% \n  mutate(prop = n/sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  class     n  prop\n  <fct> <int> <dbl>\n1 PS      975 0.644\n2 WS      539 0.356\n```\n:::\n\n```{.r .cell-code}\n# testset proporties volgens class\ncell_test %>% \n  count(class) %>% \n  mutate(prop = n/sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  class     n  prop\n  <fct> <int> <dbl>\n1 PS      325 0.644\n2 WS      180 0.356\n```\n:::\n:::\n\n\nHet meeste modelleerwerk wordt op de trainingset uitgevoerd.\n\n## Modelleren\n\nEen van de voordelen van een random forest model is dat het zeer onderhoudsarm is; het vereist zeer weinig voorbewerking van de gegevens en de standaardparameters geven doorgaans redelijke resultaten. Om die reden zullen we geen recept maken voor de celgegevens en gaan meteen aan de slag.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_mod <-\n        rand_forest(trees = 1000) %>%\n        set_engine(\"ranger\") %>%\n        set_mode(\"classification\")\n```\n:::\n\n\nDit nieuwe object `rf_fit` is het model dat we hebben getraind op de trainingsgegevensverzameling\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nrf_fit <-\n        rf_mod %>%\n        fit(class ~ ., data = cell_train)\n```\n:::\n\n\n## Schatten van de performance\n\nPrestaties kunnen worden gemeten aan de hand van de algemene classificatienauwkeurigheid en de Receiver Operating Characteristic (ROC) curve. Het `yardstick`-pakket heeft functies voor het berekenen van beide maten, genaamd `roc_auc()` en `accuracy()`. Gebruik hiervoor niet de trainingsset. Je moet de trainingsset opnieuw bewerken om betrouwbare schattingen te krijgen.\n\nDaarom modelleren we het opnieuw maar nu met `resample`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n set.seed(345)\n        folds <- vfold_cv(cell_train, v = 10)\n        folds\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n#  10-fold cross-validation \n# A tibble: 10 × 2\n   splits             id    \n   <list>             <chr> \n 1 <split [1362/152]> Fold01\n 2 <split [1362/152]> Fold02\n 3 <split [1362/152]> Fold03\n 4 <split [1362/152]> Fold04\n 5 <split [1363/151]> Fold05\n 6 <split [1363/151]> Fold06\n 7 <split [1363/151]> Fold07\n 8 <split [1363/151]> Fold08\n 9 <split [1363/151]> Fold09\n10 <split [1363/151]> Fold10\n```\n:::\n\n```{.r .cell-code}\n        rf_wf <-\n                workflow() %>%\n                add_model(rf_mod) %>%\n                add_formula(class ~ .)\n```\n:::\n\n\nDe kolom `.metrics` bevat de prestatiestatistieken die uit de 10 beoordelingssets zijn gemaakt. Deze kunnen handmatig worden ontnomen, maar het `tune`-pakket bevat een aantal eenvoudige functies die deze gegevens kunnen extraheren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  set.seed(456)\n        rf_fit_rs <-\n                rf_wf %>%\n                fit_resamples(folds)\n## Om de metrieken te krijgen ----\n        collect_metrics(rf_fit_rs)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 6\n  .metric  .estimator  mean     n std_err .config             \n  <chr>    <chr>      <dbl> <int>   <dbl> <chr>               \n1 accuracy binary     0.832    10 0.00952 Preprocessor1_Model1\n2 roc_auc  binary     0.904    10 0.00610 Preprocessor1_Model1\n```\n:::\n:::\n\n\n## Conclusie\n\nDenk aan de waarden die we nu hebben voor nauwkeurigheid en AUC. Deze prestatiecijfers zijn nu realistischer (d.w.z. lager) dan onze eerste poging om prestatiecijfers te berekenen in de handleiding hierboven.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_testing_pred <-                      # originele slechte idee\n        predict(rf_fit, cell_test) %>%\n        bind_cols(predict(rf_fit, cell_test, type = \"prob\")) %>%\n        bind_cols(cell_test %>% select(class))\nrf_testing_pred %>%                   # testset voorspellingen\n        roc_auc(truth = class, .pred_PS)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 roc_auc binary         0.891\n```\n:::\n\n```{.r .cell-code}\nrf_testing_pred %>%                   # test set voorspellingen\n        accuracy(truth = class, .pred_class)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  .metric  .estimator .estimate\n  <chr>    <chr>          <dbl>\n1 accuracy binary         0.816\n```\n:::\n:::\n\n\n# Handleiding 4: Hyperparameters\n\nSommige modelparameters kunnen tijdens de modeltraining niet rechtstreeks uit een dataset worden geleerd; dit soort parameters worden hyperparameters genoemd. Enkele voorbeelden van hyperparameters zijn het aantal voorspellers dat wordt bemonsterd bij splitsingen in een 'tree'model (wij noemen dit `mtry` in tidymodels) of de leersnelheid in een 'boosted tree'model (wij noemen dit learn_rate). In plaats van dit soort hyperparameters te leren tijdens de modeltraining, kunnen we de beste waarden voor deze waarden schatten door veel modellen te trainen op opnieuw gesampelde gegevenssets en te onderzoeken hoe goed al deze modellen presteren. Dit proces heet [tuning](url:%20https://www.tidymodels.org/start/tuning/)\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# tidymodels heb je al geopend met daarin het tune pakket met de andere pakketten\n# andere pakketten\n# modeldata, voor de cellen data, ook al geopend\n# vip om het belang van variabelen te plotten\nlibrary(vip)         # \n```\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttaching package: 'vip'\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nThe following object is masked from 'package:utils':\n\n    vi\n```\n:::\n:::\n\n\nDe data openen\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# door experts gelabelled als 'well-segmented' (WS) of 'poorly segmented' (PS).\ndata(cells, package = \"modeldata\")\ncells\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2,019 × 58\n   case  class angle_c…¹ area_…² avg_i…³ avg_i…⁴ avg_i…⁵ avg_i…⁶ conve…⁷ conve…⁸\n   <fct> <fct>     <dbl>   <int>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n 1 Test  PS       143.       185    15.7    4.95    9.55    2.21    1.12   0.920\n 2 Train PS       134.       819    31.9  207.     69.9   164.      1.26   0.797\n 3 Train WS       107.       431    28.0  116.     63.9   107.      1.05   0.935\n 4 Train PS        69.2      298    19.5  102.     28.2    31.0     1.20   0.866\n 5 Test  PS         2.89     285    24.3  112.     20.5    40.6     1.11   0.957\n 6 Test  WS        40.7      172   326.   654.    129.    347.      1.01   0.993\n 7 Test  WS       174.       177   260.   596.    124.    273.      1.01   0.984\n 8 Test  PS       180.       251    18.3    5.73   17.2     1.55    1.20   0.831\n 9 Test  WS        18.9      495    16.1   89.5    13.7    51.4     1.19   0.822\n10 Test  WS       153.       384    17.7   89.9    20.4    63.1     1.16   0.865\n# … with 2,009 more rows, 48 more variables: diff_inten_density_ch_1 <dbl>,\n#   diff_inten_density_ch_3 <dbl>, diff_inten_density_ch_4 <dbl>,\n#   entropy_inten_ch_1 <dbl>, entropy_inten_ch_3 <dbl>,\n#   entropy_inten_ch_4 <dbl>, eq_circ_diam_ch_1 <dbl>,\n#   eq_ellipse_lwr_ch_1 <dbl>, eq_ellipse_oblate_vol_ch_1 <dbl>,\n#   eq_ellipse_prolate_vol_ch_1 <dbl>, eq_sphere_area_ch_1 <dbl>,\n#   eq_sphere_vol_ch_1 <dbl>, fiber_align_2_ch_3 <dbl>, …\n```\n:::\n:::\n\n\n## Voorspellen van beeldsegmentatie maar nu beter\n\nRandom forest-modellen is een methode om bomen te schatten en die presteren doorgaans goed met standaard hyperparameters. De nauwkeurigheid van sommige andere soortgelijke modellen kan echter gevoelig zijn voor de waarden van de hyperparameters. In dit artikel zullen we een beslisboommodel (decision tree model) trainen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\ncell_split <- initial_split(cells %>% select(-case),\n                            strata = class)\ncell_train <- training(cell_split)\ncell_test  <- testing(cell_split)\n```\n:::\n\n\n# Hyperparameters afstemmen\n\nLaten we beginnen met het `parsnip` pakket, met een `decision_tree()` model met de `rpart` engine. Om de hyperparameters `cost_complexity` en `tree_depth` van de beslisboom te tunen, maken we een modelspecificatie die aangeeft welke hyperparameters we willen tunen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune_spec <-\n        decision_tree(\n                cost_complexity = tune(),\n                tree_depth = tune()\n        ) %>%\n        set_engine(\"rpart\") %>%\n        set_mode(\"classification\")\ntune_spec\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = tune()\n  tree_depth = tune()\n\nComputational engine: rpart \n```\n:::\n\n```{.r .cell-code}\n## dials::grid_regular() \ntree_grid <- grid_regular(cost_complexity(),\n                          tree_depth(),\n                          levels = 5)\ntree_grid\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 25 × 2\n   cost_complexity tree_depth\n             <dbl>      <int>\n 1    0.0000000001          1\n 2    0.0000000178          1\n 3    0.00000316            1\n 4    0.000562              1\n 5    0.1                   1\n 6    0.0000000001          4\n 7    0.0000000178          4\n 8    0.00000316            4\n 9    0.000562              4\n10    0.1                   4\n# … with 15 more rows\n```\n:::\n:::\n\n\nGewapend met ons raster gevuld met 25 kandidaat-beslisboommodellen, laten we cross-validatie maken voor tuning:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\ncell_folds <- vfold_cv(cell_train)\n```\n:::\n\n\nWe zijn klaar voor het afstellen! Laten we `tune_grid()` gebruiken om modellen te passen bij alle verschillende waarden die we hebben gekozen voor elke afgestemde hyperparameter. Er zijn verschillende mogelijkheden om het object voor tuning te bouwen:\n\n-   Stem een modelspecificatie af samen met een recept of model, of\\\n-   Een workflow() afstemmen die een modelspecificatie en een recept of model preprocessor bundelt.\\\n    Hier gebruiken we een `workflow()` met een eenvoudige formule; indien dit model een meer gecompliceerde gegevensvoorbewerking vereist, zouden we `add_recipe()` kunnen gebruiken in plaats van `add_formula()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n set.seed(345)\n        tree_wf <- workflow() %>%\n                add_model(tune_spec) %>%\n                add_formula(class ~ .)\n```\n:::\n\n\nZodra we onze resultaten over het afstellen hebben, kunnen we ze zowel via visualisatie verkennen als het beste resultaat selecteren.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n tree_res <-\n                tree_wf %>%\n                tune_grid(\n                        resamples = cell_folds,\n                        grid = tree_grid\n                )\n        tree_res\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Tuning results\n# 10-fold cross-validation \n# A tibble: 10 × 4\n   splits             id     .metrics          .notes          \n   <list>             <chr>  <list>            <list>          \n 1 <split [1362/152]> Fold01 <tibble [50 × 6]> <tibble [0 × 3]>\n 2 <split [1362/152]> Fold02 <tibble [50 × 6]> <tibble [0 × 3]>\n 3 <split [1362/152]> Fold03 <tibble [50 × 6]> <tibble [0 × 3]>\n 4 <split [1362/152]> Fold04 <tibble [50 × 6]> <tibble [0 × 3]>\n 5 <split [1363/151]> Fold05 <tibble [50 × 6]> <tibble [0 × 3]>\n 6 <split [1363/151]> Fold06 <tibble [50 × 6]> <tibble [0 × 3]>\n 7 <split [1363/151]> Fold07 <tibble [50 × 6]> <tibble [0 × 3]>\n 8 <split [1363/151]> Fold08 <tibble [50 × 6]> <tibble [0 × 3]>\n 9 <split [1363/151]> Fold09 <tibble [50 × 6]> <tibble [0 × 3]>\n10 <split [1363/151]> Fold10 <tibble [50 × 6]> <tibble [0 × 3]>\n```\n:::\n:::\n\n\nDe functie `collect_metrics()` geeft ons een nette tabel met alle resultaten. We hadden 25 kandidaat-modellen en twee metrieken, `accuracy` en `roc_auc`, en we krijgen een rij voor elke .metriek en model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>% \n  collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 50 × 8\n   cost_complexity tree_depth .metric  .estimator  mean     n std_err .config   \n             <dbl>      <int> <chr>    <chr>      <dbl> <int>   <dbl> <chr>     \n 1    0.0000000001          1 accuracy binary     0.732    10  0.0148 Preproces…\n 2    0.0000000001          1 roc_auc  binary     0.777    10  0.0107 Preproces…\n 3    0.0000000178          1 accuracy binary     0.732    10  0.0148 Preproces…\n 4    0.0000000178          1 roc_auc  binary     0.777    10  0.0107 Preproces…\n 5    0.00000316            1 accuracy binary     0.732    10  0.0148 Preproces…\n 6    0.00000316            1 roc_auc  binary     0.777    10  0.0107 Preproces…\n 7    0.000562              1 accuracy binary     0.732    10  0.0148 Preproces…\n 8    0.000562              1 roc_auc  binary     0.777    10  0.0107 Preproces…\n 9    0.1                   1 accuracy binary     0.732    10  0.0148 Preproces…\n10    0.1                   1 roc_auc  binary     0.777    10  0.0107 Preproces…\n# … with 40 more rows\n```\n:::\n:::\n\n\nLaten we er een grafiek van maken.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntree_res %>%\n                collect_metrics() %>%\n                mutate(tree_depth = factor(tree_depth)) %>%\n                ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n                geom_line(size = 1.5, alpha = 0.6) +\n                geom_point(size = 2) +\n                facet_wrap(~ .metric, scales = \"free\", nrow = 2) +\n                scale_x_log10(labels = scales::label_number()) +\n                scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n```\n:::\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-46-1.png){width=672}\n:::\n\n```{.r .cell-code}\n## Wat is de beste?\nbest_tree <- tree_res %>%\n                select_best(\"roc_auc\")\n        best_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            <dbl>      <int> <chr>                \n1        0.000562         11 Preprocessor1_Model19\n```\n:::\n:::\n\n\n# Afronden\n\nWij kunnen ons workflow-object `tree_wf` bijwerken (of \"finaliseren\") met de waarden van `select_best()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n final_wf <-\n                tree_wf %>%\n                finalize_workflow(best_tree)\n        final_wf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow ════════════════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nclass ~ .\n\n── Model ───────────────────────────────────────────────────────────────────────\nDecision Tree Model Specification (classification)\n\nMain Arguments:\n  cost_complexity = 0.000562341325190349\n  tree_depth = 11\n\nComputational engine: rpart \n```\n:::\n:::\n\n\n## Laatste fit\n\nTot slot passen we dit definitieve model toe op de opleidingsgegevens en gebruiken we onze testgegevens om de modelprestatie te schatten die we verwachten te zien met nieuwe gegevens. Wij kunnen de functie `last_fit()` gebruiken voor ons definitieve model; deze functie past het definitieve model toe op de volledige reeks opleidingsgegevens en evalueert het definitieve model op de testgegevens.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_tree <-\n            final_wf %>%\n            fit(data = cell_train)\n\nfinal_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nclass ~ .\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 1514 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 1514 539 PS (0.64398943 0.35601057)  \n     2) total_inten_ch_2< 41732.5 642  33 PS (0.94859813 0.05140187)  \n       4) shape_p_2_a_ch_1>=1.251801 631  27 PS (0.95721078 0.04278922)  \n         8) avg_inten_ch_2< 125.8919 525  12 PS (0.97714286 0.02285714) *\n         9) avg_inten_ch_2>=125.8919 106  15 PS (0.85849057 0.14150943)  \n          18) var_inten_ch_4>=39.85951 82   6 PS (0.92682927 0.07317073) *\n          19) var_inten_ch_4< 39.85951 24   9 PS (0.62500000 0.37500000)  \n            38) inten_cooc_asm_ch_4>=0.2197672 12   0 PS (1.00000000 0.00000000) *\n            39) inten_cooc_asm_ch_4< 0.2197672 12   3 WS (0.25000000 0.75000000) *\n       5) shape_p_2_a_ch_1< 1.251801 11   5 WS (0.45454545 0.54545455) *\n     3) total_inten_ch_2>=41732.5 872 366 WS (0.41972477 0.58027523)  \n       6) fiber_width_ch_1< 11.37318 406 160 PS (0.60591133 0.39408867)  \n        12) avg_inten_ch_1< 145.4883 293  85 PS (0.70989761 0.29010239)  \n          24) fiber_width_ch_1< 7.878131 68   5 PS (0.92647059 0.07352941) *\n          25) fiber_width_ch_1>=7.878131 225  80 PS (0.64444444 0.35555556)  \n            50) total_inten_ch_1< 12969.5 74  15 PS (0.79729730 0.20270270)  \n             100) inten_cooc_asm_ch_4< 0.06289989 34   2 PS (0.94117647 0.05882353) *\n             101) inten_cooc_asm_ch_4>=0.06289989 40  13 PS (0.67500000 0.32500000)  \n               202) neighbor_min_dist_ch_1>=32.71331 9   0 PS (1.00000000 0.00000000) *\n               203) neighbor_min_dist_ch_1< 32.71331 31  13 PS (0.58064516 0.41935484)  \n                 406) skew_inten_ch_4>=1.060929 16   3 PS (0.81250000 0.18750000) *\n                 407) skew_inten_ch_4< 1.060929 15   5 WS (0.33333333 0.66666667) *\n            51) total_inten_ch_1>=12969.5 151  65 PS (0.56953642 0.43046358)  \n             102) kurt_inten_ch_1>=-0.3447192 110  37 PS (0.66363636 0.33636364)  \n               204) diff_inten_density_ch_4>=112.6034 35   5 PS (0.85714286 0.14285714) *\n               205) diff_inten_density_ch_4< 112.6034 75  32 PS (0.57333333 0.42666667)  \n                 410) inten_cooc_contrast_ch_4< 3.122366 11   0 PS (1.00000000 0.00000000) *\n                 411) inten_cooc_contrast_ch_4>=3.122366 64  32 PS (0.50000000 0.50000000)  \n                   822) fiber_align_2_ch_4>=1.591445 11   1 PS (0.90909091 0.09090909) *\n                   823) fiber_align_2_ch_4< 1.591445 53  22 WS (0.41509434 0.58490566)  \n                    1646) neighbor_avg_dist_ch_1< 217.8143 21   7 PS (0.66666667 0.33333333)  \n                      3292) eq_ellipse_lwr_ch_1>=1.942086 14   2 PS (0.85714286 0.14285714) *\n                      3293) eq_ellipse_lwr_ch_1< 1.942086 7   2 WS (0.28571429 0.71428571) *\n                    1647) neighbor_avg_dist_ch_1>=217.8143 32   8 WS (0.25000000 0.75000000) *\n             103) kurt_inten_ch_1< -0.3447192 41  13 WS (0.31707317 0.68292683)  \n               206) shape_bfr_ch_1>=0.635439 12   5 PS (0.58333333 0.41666667) *\n               207) shape_bfr_ch_1< 0.635439 29   6 WS (0.20689655 0.79310345)  \n                 414) shape_bfr_ch_1< 0.5196834 7   3 PS (0.57142857 0.42857143) *\n                 415) shape_bfr_ch_1>=0.5196834 22   2 WS (0.09090909 0.90909091) *\n        13) avg_inten_ch_1>=145.4883 113  38 WS (0.33628319 0.66371681)  \n          26) total_inten_ch_3>=57919.5 33  10 PS (0.69696970 0.30303030)  \n            52) spot_fiber_count_ch_3< 2.5 24   4 PS (0.83333333 0.16666667)  \n             104) kurt_inten_ch_1>=-0.335807 17   0 PS (1.00000000 0.00000000) *\n             105) kurt_inten_ch_1< -0.335807 7   3 WS (0.42857143 0.57142857) *\n            53) spot_fiber_count_ch_3>=2.5 9   3 WS (0.33333333 0.66666667) *\n\n...\nand 40 more lines.\n```\n:::\n\n```{.r .cell-code}\n## variabele belang\nlibrary(vip)\nfinal_tree %>%\n                pull_workflow_fit() %>%\n                vip(geom = \"point\")\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-48-1.png){width=672}\n:::\n:::\n\n\nTot slot passen we dit definitieve model toe op de trainingsgegevens en gebruiken we onze testgegevens om de modelprestatie te schatten die we verwachten te zien met nieuwe gegevens.\n\nWij kunnen de functie `last_fit()` gebruiken voor ons definitieve model; deze functie past het definitieve model toe op de volledige reeks trainingsgegevens en evalueert het definitieve model op de testgegevens.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fit <-\n          final_wf %>%\n          last_fit(cell_split)\n## verzamel de metrieken\nfinal_fit %>%\n          collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.758 Preprocessor1_Model1\n2 roc_auc  binary         0.839 Preprocessor1_Model1\n```\n:::\n:::\n\n\nToon nog even de ROC-curve.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n final_fit %>%\n                collect_predictions() %>%\n                roc_curve(class, .pred_PS) %>%\n                autoplot()\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-50-1.png){width=672}\n:::\n:::\n\n\nDe prestatiecijfers van de testset geven aan dat we tijdens onze tuneprocedure niet te veel hebben aangepast.\n\nHet object `final_fit` bevat een definitieve, passende workflow die je kunt gebruiken voor voorspellingen op nieuwe gegevens of om de resultaten verder te begrijpen. Je kunt dit object uitpakken met een van de helpfuncties extract\\_.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_tree <- extract_workflow(final_fit)\nfinal_tree\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Formula\nModel: decision_tree()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\nclass ~ .\n\n── Model ───────────────────────────────────────────────────────────────────────\nn= 1514 \n\nnode), split, n, loss, yval, (yprob)\n      * denotes terminal node\n\n   1) root 1514 539 PS (0.64398943 0.35601057)  \n     2) total_inten_ch_2< 41732.5 642  33 PS (0.94859813 0.05140187)  \n       4) shape_p_2_a_ch_1>=1.251801 631  27 PS (0.95721078 0.04278922)  \n         8) avg_inten_ch_2< 125.8919 525  12 PS (0.97714286 0.02285714) *\n         9) avg_inten_ch_2>=125.8919 106  15 PS (0.85849057 0.14150943)  \n          18) var_inten_ch_4>=39.85951 82   6 PS (0.92682927 0.07317073) *\n          19) var_inten_ch_4< 39.85951 24   9 PS (0.62500000 0.37500000)  \n            38) inten_cooc_asm_ch_4>=0.2197672 12   0 PS (1.00000000 0.00000000) *\n            39) inten_cooc_asm_ch_4< 0.2197672 12   3 WS (0.25000000 0.75000000) *\n       5) shape_p_2_a_ch_1< 1.251801 11   5 WS (0.45454545 0.54545455) *\n     3) total_inten_ch_2>=41732.5 872 366 WS (0.41972477 0.58027523)  \n       6) fiber_width_ch_1< 11.37318 406 160 PS (0.60591133 0.39408867)  \n        12) avg_inten_ch_1< 145.4883 293  85 PS (0.70989761 0.29010239)  \n          24) fiber_width_ch_1< 7.878131 68   5 PS (0.92647059 0.07352941) *\n          25) fiber_width_ch_1>=7.878131 225  80 PS (0.64444444 0.35555556)  \n            50) total_inten_ch_1< 12969.5 74  15 PS (0.79729730 0.20270270)  \n             100) inten_cooc_asm_ch_4< 0.06289989 34   2 PS (0.94117647 0.05882353) *\n             101) inten_cooc_asm_ch_4>=0.06289989 40  13 PS (0.67500000 0.32500000)  \n               202) neighbor_min_dist_ch_1>=32.71331 9   0 PS (1.00000000 0.00000000) *\n               203) neighbor_min_dist_ch_1< 32.71331 31  13 PS (0.58064516 0.41935484)  \n                 406) skew_inten_ch_4>=1.060929 16   3 PS (0.81250000 0.18750000) *\n                 407) skew_inten_ch_4< 1.060929 15   5 WS (0.33333333 0.66666667) *\n            51) total_inten_ch_1>=12969.5 151  65 PS (0.56953642 0.43046358)  \n             102) kurt_inten_ch_1>=-0.3447192 110  37 PS (0.66363636 0.33636364)  \n               204) diff_inten_density_ch_4>=112.6034 35   5 PS (0.85714286 0.14285714) *\n               205) diff_inten_density_ch_4< 112.6034 75  32 PS (0.57333333 0.42666667)  \n                 410) inten_cooc_contrast_ch_4< 3.122366 11   0 PS (1.00000000 0.00000000) *\n                 411) inten_cooc_contrast_ch_4>=3.122366 64  32 PS (0.50000000 0.50000000)  \n                   822) fiber_align_2_ch_4>=1.591445 11   1 PS (0.90909091 0.09090909) *\n                   823) fiber_align_2_ch_4< 1.591445 53  22 WS (0.41509434 0.58490566)  \n                    1646) neighbor_avg_dist_ch_1< 217.8143 21   7 PS (0.66666667 0.33333333)  \n                      3292) eq_ellipse_lwr_ch_1>=1.942086 14   2 PS (0.85714286 0.14285714) *\n                      3293) eq_ellipse_lwr_ch_1< 1.942086 7   2 WS (0.28571429 0.71428571) *\n                    1647) neighbor_avg_dist_ch_1>=217.8143 32   8 WS (0.25000000 0.75000000) *\n             103) kurt_inten_ch_1< -0.3447192 41  13 WS (0.31707317 0.68292683)  \n               206) shape_bfr_ch_1>=0.635439 12   5 PS (0.58333333 0.41666667) *\n               207) shape_bfr_ch_1< 0.635439 29   6 WS (0.20689655 0.79310345)  \n                 414) shape_bfr_ch_1< 0.5196834 7   3 PS (0.57142857 0.42857143) *\n                 415) shape_bfr_ch_1>=0.5196834 22   2 WS (0.09090909 0.90909091) *\n        13) avg_inten_ch_1>=145.4883 113  38 WS (0.33628319 0.66371681)  \n          26) total_inten_ch_3>=57919.5 33  10 PS (0.69696970 0.30303030)  \n            52) spot_fiber_count_ch_3< 2.5 24   4 PS (0.83333333 0.16666667)  \n             104) kurt_inten_ch_1>=-0.335807 17   0 PS (1.00000000 0.00000000) *\n             105) kurt_inten_ch_1< -0.335807 7   3 WS (0.42857143 0.57142857) *\n            53) spot_fiber_count_ch_3>=2.5 9   3 WS (0.33333333 0.66666667) *\n\n...\nand 40 more lines.\n```\n:::\n:::\n\n\nMisschien willen we ook begrijpen welke variabelen belangrijk zijn in dit uiteindelijke model. Wij kunnen het `vip`-pakket gebruiken om het belang van variabelen te schatten op basis van de structuur van het model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(vip)\n\nfinal_tree %>% \n  extract_fit_parsnip() %>% \n  vip()\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-52-1.png){width=672}\n:::\n:::\n\n\nDit zijn de geautomatiseerde beeldanalysemetingen die het belangrijkst zijn voor de voorspelling van de segmentatiekwaliteit.\n\nWe laten het aan de lezer over om te onderzoeken of zij een andere beslisboom-hyperparameter willen afstemmen. Daarvoor kun je de referentiedocumenten raadplegen,of de functie `args()` gebruiken om te zien welke `parsnip`-objectargumenten beschikbaar zijn:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nargs(decision_tree)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nfunction (mode = \"unknown\", engine = \"rpart\", cost_complexity = NULL, \n    tree_depth = NULL, min_n = NULL) \nNULL\n```\n:::\n:::\n\n\n# Handleiding 5: Case-studie\n\nDe vier handleiding hiervoor waren steeds gericht op één taak met betrekking tot modelleren. Onderweg hebben we ook de kernpakketten in het tidymodels ecosysteem geïntroduceerd en enkele van de belangrijkste functies die je nodig hebt om met modellen te gaan werken.\n\nDe vijfde en laatste handleiding is een case-studie waarin we de voorgaande kennis gebruiken als basis om een voorspellend model van begin tot eind te bouwen met gegevens over hotelovernachtingen [case-studie](url:%20https://www.tidymodels.org/start/case-study/).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##  tidymodels moet geïnstalleerd zijn evenals vip\n## Verder:\nlibrary(readr)       \n# voor importeren van data\n```\n:::\n\n\n## Data\n\nEerst de data binnenhalen, iets aanpassen en bekijken.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n##  Inlezen\nhotels <-\n                read_csv('https://tidymodels.org/start/case-study/hotels.csv') %>%\n                mutate_if(is.character, as.factor)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nRows: 50000 Columns: 23\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (11): hotel, children, meal, country, market_segment, distribution_chan...\ndbl  (11): lead_time, stays_in_weekend_nights, stays_in_week_nights, adults,...\ndate  (1): arrival_date\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n\n```{.r .cell-code}\ndim(hotels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 50000    23\n```\n:::\n:::\n\n\nAllicht alle variabelen nog eens goed bekijken.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n glimpse(hotels)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 50,000\nColumns: 23\n$ hotel                          <fct> City_Hotel, City_Hotel, Resort_Hotel, R…\n$ lead_time                      <dbl> 217, 2, 95, 143, 136, 67, 47, 56, 80, 6…\n$ stays_in_weekend_nights        <dbl> 1, 0, 2, 2, 1, 2, 0, 0, 0, 2, 1, 0, 1, …\n$ stays_in_week_nights           <dbl> 3, 1, 5, 6, 4, 2, 2, 3, 4, 2, 2, 1, 2, …\n$ adults                         <dbl> 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 1, 2, …\n$ children                       <fct> none, none, none, none, none, none, chi…\n$ meal                           <fct> BB, BB, BB, HB, HB, SC, BB, BB, BB, BB,…\n$ country                        <fct> DEU, PRT, GBR, ROU, PRT, GBR, ESP, ESP,…\n$ market_segment                 <fct> Offline_TA/TO, Direct, Online_TA, Onlin…\n$ distribution_channel           <fct> TA/TO, Direct, TA/TO, TA/TO, Direct, TA…\n$ is_repeated_guest              <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ previous_cancellations         <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ previous_bookings_not_canceled <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ reserved_room_type             <fct> A, D, A, A, F, A, C, B, D, A, A, D, A, …\n$ assigned_room_type             <fct> A, K, A, A, F, A, C, A, D, A, D, D, A, …\n$ booking_changes                <dbl> 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ deposit_type                   <fct> No_Deposit, No_Deposit, No_Deposit, No_…\n$ days_in_waiting_list           <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ customer_type                  <fct> Transient-Party, Transient, Transient, …\n$ average_daily_rate             <dbl> 80.75, 170.00, 8.00, 81.00, 157.60, 49.…\n$ required_car_parking_spaces    <fct> none, none, none, none, none, none, non…\n$ total_of_special_requests      <dbl> 1, 3, 2, 1, 4, 1, 1, 1, 1, 1, 0, 1, 0, …\n$ arrival_date                   <date> 2016-09-01, 2017-08-25, 2016-11-19, 20…\n```\n:::\n:::\n\n\nDe uitkomst variabele is `children`, een factorvariabele met twee niveaus (wel of geen kinderen. 8,1% van de gasten heeft kinderen bij zich tijdens de hotelovernachtingen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhotels %>%\n                count(children) %>%\n                mutate(prop = n/sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  children     n   prop\n  <fct>    <int>  <dbl>\n1 children  4038 0.0808\n2 none     45962 0.919 \n```\n:::\n:::\n\n\n## Splitsen van data\n\nWe reserveren 25% van de data voor de test-data. De variabele `children` is behoorlijk uit balans, dus we stratificeren de dataset op deze variabele als we deze opsplitsen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\n        splits      <- initial_split(hotels, strata = children)\n        hotel_other <- training(splits)\n        hotel_test  <- testing(splits)\n```\n:::\n\n\nZo ziet de trainingsset er nu uit qua `children` variabele.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhotel_other %>%\n                count(children) %>%\n                mutate(prop = n/sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  children     n   prop\n  <fct>    <int>  <dbl>\n1 children  3027 0.0807\n2 none     34473 0.919 \n```\n:::\n:::\n\n\nZo ziet de testtest eruit op dezelfde variabele, vergelijkbaar:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhotel_test  %>%\n                count(children) %>%\n                mutate(prop = n/sum(n))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 3\n  children     n   prop\n  <fct>    <int>  <dbl>\n1 children  1011 0.0809\n2 none     11489 0.919 \n```\n:::\n:::\n\n\nVan de trainingsset maken we ook nog een aparte validitatie set. De\n\n![Opzet](Screenshot1.png)\n\nZo ziet het er dan uit.\n\nWe gebruiken de functie `validation_split()` om 20% van de `hotel_other` verblijven toe te wijzen aan de validatieset en 30.000 verblijven aan de trainingset. Dit betekent dat de prestatiecijfers van ons model worden berekend op een enkele set van 7.500 hotelovernachtingen. Dat is vrij groot, dus de hoeveelheid gegevens zou voldoende precisie moeten opleveren om een betrouwbare indicator te zijn voor hoe goed elk model de uitkomst voorspelt met een enkele iteratie van resampling.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n set.seed(234)\n        val_set <- validation_split(hotel_other,\n                                    strata = children,\n                                    prop = 0.80)\n```\n:::\n\n\nOok dit hebben we gestratificeerd op de uitkomstvariabele `children`.\n\n## Eerste model\n\nHier wordt, en ik gebruik toch maar even de Engelse woorden, een 'penalized logistic regression' model gebruikt via `glmnet`. De `penalty=tune(),mixture = 1` haalt irrelevante predictoren weg.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  lr_mod <-\n                logistic_reg(penalty = tune(), mixture = 1) %>%\n                set_engine(\"glmnet\")\n```\n:::\n\n\nVia het pakket `recipe` dat in `tidymodels` zit kun je enkele aanvullende voorbereidende handelingen verrichten. Zoals:\n\n\\- `step_date()` creëert voorspellers voor het jaar, de maand en de dag van de week.\\\n- `step_holiday()` genereert een reeks indicatorvariabelen voor specifieke feestdagen. Hoewel we niet weten waar deze twee hotels zich bevinden, weten we wel dat de landen van herkomst voor de meeste verblijven in Europa liggen.\\\n- `step_rm()` verwijdert variabelen; hier gebruiken we het om de oorspronkelijke datumvariabele te verwijderen omdat we die niet langer in het model willen.\n\nBovendien moeten alle categorische voorspellers (bv. `distribution-channel`, `hotel`, ...) worden omgezet naar dummy-variabelen en moeten alle numerieke voorspellers worden gecentreerd en geschaald.\n\n`- step_dummy()` zet tekens of factoren (d.w.z. nominale variabelen) om in een of meer numerieke binaire modeltermen voor de niveaus van de oorspronkelijke gegevens.\\\n- `step_zv()` verwijdert indicatorvariabelen die slechts één unieke waarde bevatten (bv. allemaal nullen). Dit is belangrijk omdat voor gestrafte modellen de voorspellers moeten worden gecentreerd en geschaald.\n\n`- step_normalize()` centreert en schaalt numerieke variabelen.\n\n\\\nAls we al deze stappen samenvoegen tot een recept voor ons gekozen model ('penalized logistic regression\\`), hebben we:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nholidays <- c(\"AllSouls\", \"AshWednesday\", \"ChristmasEve\", \"Easter\",\n                      \"ChristmasDay\", \"GoodFriday\", \"NewYearsDay\", \"PalmSunday\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n lr_recipe <-\n                recipe(children ~ ., data = hotel_other) %>%\n                step_date(arrival_date) %>%\n                step_holiday(arrival_date, holidays = holidays) %>%\n                step_rm(arrival_date) %>%\n                step_dummy(all_nominal(), -all_outcomes()) %>%\n                step_zv(all_predictors()) %>%\n                step_normalize(all_predictors())\n```\n:::\n\n\nLaten we nu alles ('model en 'recipe') in een `workflow` plaatsen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n lr_workflow <-\n                workflow() %>%\n                add_model(lr_mod) %>%\n                add_recipe(lr_recipe)\n```\n:::\n\n\nWelke penalties moeten we gebruiken? Omdat we slechts een hyperparameter hoeven af te stellen, gebruiken we een grid met 30 verschillende waarden in een kolom.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 30))\n        lr_reg_grid %>% top_n(-5) # lowest penalty values\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSelecting by penalty\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 1\n   penalty\n     <dbl>\n1 0.0001  \n2 0.000127\n3 0.000161\n4 0.000204\n5 0.000259\n```\n:::\n\n```{.r .cell-code}\n        lr_reg_grid %>% top_n(5)  # highest penalty values\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nSelecting by penalty\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 1\n  penalty\n    <dbl>\n1  0.0386\n2  0.0489\n3  0.0621\n4  0.0788\n5  0.1   \n```\n:::\n\n```{.r .cell-code}\n        ## 4.5 Train & Tune ----\n        lr_res <-\n                lr_workflow %>%\n                tune_grid(val_set,\n                          grid = lr_reg_grid,\n                          control = control_grid(save_pred = TRUE),\n                          metrics = metric_set(roc_auc))\n```\n:::\n\n\nHet is makkelijk om de validatieset metrieken te visualiseren door het gebied onder de ROC-curve uit te zetten tegen de reeks van waarden:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n lr_plot <-\n                lr_res %>%\n                collect_metrics() %>%\n                ggplot(aes(x = penalty, y = mean)) +\n                geom_point() +\n                geom_line() +\n                ylab(\"Gebied onder de ROC Curve\") +\n                scale_x_log10(labels = scales::label_number())\n\n        lr_plot\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-67-1.png){width=672}\n:::\n:::\n\n\nDe prestaties van ons model lijken overall het beste te doen bij de kleinere strafwaarden. Als we alleen uitgaan van de roc_auc-metriek zouden we meerdere opties voor de \"beste\" waarde van deze hyperparameter kunnen vinden:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntop_models <-\n  lr_res %>% \n  show_best(\"roc_auc\", n = 15) %>% \n  arrange(penalty) \ntop_models\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 15 × 7\n    penalty .metric .estimator  mean     n std_err .config              \n      <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1 0.000127 roc_auc binary     0.872     1      NA Preprocessor1_Model02\n 2 0.000161 roc_auc binary     0.872     1      NA Preprocessor1_Model03\n 3 0.000204 roc_auc binary     0.873     1      NA Preprocessor1_Model04\n 4 0.000259 roc_auc binary     0.873     1      NA Preprocessor1_Model05\n 5 0.000329 roc_auc binary     0.874     1      NA Preprocessor1_Model06\n 6 0.000418 roc_auc binary     0.874     1      NA Preprocessor1_Model07\n 7 0.000530 roc_auc binary     0.875     1      NA Preprocessor1_Model08\n 8 0.000672 roc_auc binary     0.875     1      NA Preprocessor1_Model09\n 9 0.000853 roc_auc binary     0.876     1      NA Preprocessor1_Model10\n10 0.00108  roc_auc binary     0.876     1      NA Preprocessor1_Model11\n11 0.00137  roc_auc binary     0.876     1      NA Preprocessor1_Model12\n12 0.00174  roc_auc binary     0.876     1      NA Preprocessor1_Model13\n13 0.00221  roc_auc binary     0.876     1      NA Preprocessor1_Model14\n14 0.00281  roc_auc binary     0.875     1      NA Preprocessor1_Model15\n15 0.00356  roc_auc binary     0.873     1      NA Preprocessor1_Model16\n```\n:::\n:::\n\n\nAls we `select_best()` zouden gebruiken, zou dit kandidaat-model 11 opleveren met een penalty-waarde van 0,00137. Kandidaat-model 12 met een strafwaarde van 0,00174 heeft in feite dezelfde prestaties als het numeriek beste model, maar kan meer voorspellers elimineren. Laten we deze nemen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_best <- \n  lr_res %>% \n  collect_metrics() %>% \n  arrange(penalty) %>% \n  slice(12)\nlr_best\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 7\n  penalty .metric .estimator  mean     n std_err .config              \n    <dbl> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1 0.00137 roc_auc binary     0.876     1      NA Preprocessor1_Model12\n```\n:::\n:::\n\n\nLaten we deze visualiseren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlr_auc <- \n  lr_res %>% \n  collect_predictions(parameters = lr_best) %>% \n  roc_curve(children, .pred_children) %>% \n  mutate(model = \"Logistic Regression\")\n\nautoplot(lr_auc)\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-70-1.png){width=672}\n:::\n:::\n\n\nHet prestatieniveau van dit logistische regressiemodel is goed, maar niet baanbrekend. Misschien is de lineaire aard van de voorspellingsvergelijking te beperkend voor deze dataset. Als volgende stap zouden we een sterk niet-lineair model kunnen overwegen dat wordt gegenereerd met behulp van een 'vertakte'-methode.\n\n## 'Vertakte'-methode\n\nEen effectieve en onderhoudsarme modelleringstechniek is een `random forest`. Vertakte modellen vereisen zeer weinig voorbewerking en kunnen vele soorten voorspellers aan (continu, categorisch, enz.).\n\nBouw het model zo dat het de trainingstijd reduceert. Het `tune`-pakket kan parallelle verwerking voor u doen en staat gebruikers toe om meerdere processors of aparte machines te gebruiken om modellen te fitten. Zo detecteer je de processoren:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n cores <- parallel::detectCores()\n        cores\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 4\n```\n:::\n:::\n\n\nVervolgens het model bouwen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n rf_mod <-\n                rand_forest(mtry = tune(), min_n = tune(), trees = 1000) %>%\n                # tune() is voor later\n                set_engine(\"ranger\", num.threads = cores) %>%\n                set_mode(\"classification\")\n```\n:::\n\n\nOpgelet: Geen processoren vaststellen behalve voor `random forest`\n\nIn tegenstelling tot de \\`penalized logistic regression' modellen zoals hierboven gebruikt, vraagt het 'random forest model' geen dummies of genormaliseerde voorspellers.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_recipe <-\n                recipe(children ~ ., data = hotel_other) %>%\n                step_date(arrival_date) %>%\n                step_holiday(arrival_date) %>%\n                step_rm(arrival_date)\n```\n:::\n\n\nCreëer vervolgens de workflow.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n rf_workflow <-\n                workflow() %>%\n                add_model(rf_mod) %>%\n                add_recipe(rf_recipe)\n```\n:::\n\n\nTrain en stel het model af. Laat zien wat er moet worden afgesteld.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n rf_mod %>%\n                parameters()\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: `parameters.model_spec()` was deprecated in tune 0.1.6.9003.\nℹ Please use `hardhat::extract_parameter_set_dials()` instead.\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCollection of 2 parameters for tuning\n\n identifier  type    object\n       mtry  mtry nparam[?]\n      min_n min_n nparam[+]\n\nModel parameters needing finalization:\n   # Randomly Selected Predictors ('mtry')\n\nSee `?dials::finalize` or `?dials::update.parameters` for more information.\n```\n:::\n:::\n\n\nLaat zien wel ruimte je hebt.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(345)\n        rf_res <-\n                rf_workflow %>%\n                tune_grid(val_set,\n                          grid = 25,\n                          control = control_grid(save_pred = TRUE),\n                          metrics = metric_set(roc_auc))\n```\n\n::: {.cell-output .cell-output-stderr}\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n:::\n:::\n\n\nLaat zien wat de beste keuze is.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_res %>%\n                show_best(metric = \"roc_auc\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 8\n   mtry min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     8     7 roc_auc binary     0.926     1      NA Preprocessor1_Model13\n2    12     7 roc_auc binary     0.926     1      NA Preprocessor1_Model01\n3    13     4 roc_auc binary     0.925     1      NA Preprocessor1_Model05\n4     9    12 roc_auc binary     0.924     1      NA Preprocessor1_Model19\n5     6    18 roc_auc binary     0.924     1      NA Preprocessor1_Model24\n```\n:::\n:::\n\n\nHet bereik van de y-as geeft echter aan dat het model zeer robuust is voor de keuze van deze parameterwaarden --- op één na zijn alle ROC AUC-waarden groter dan 0,90.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(rf_res)\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-78-1.png){width=672}\n:::\n:::\n\n\nSelecteer de beste.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n rf_best <-\n                rf_res %>%\n                select_best(metric = \"roc_auc\")\n        rf_best\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 3\n   mtry min_n .config              \n  <int> <int> <chr>                \n1     8     7 Preprocessor1_Model13\n```\n:::\n:::\n\n\nStel het model af op de beste voorspelling.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_auc <-\n                rf_res %>%\n                collect_predictions(parameters = rf_best) %>%\n                roc_curve(children, .pred_children) %>%\n                mutate(model = \"Random Forest\")\n```\n:::\n\n\nPlot vervolgens het beste model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_rows(rf_auc, lr_auc) %>%\n                ggplot(aes(x = 1 - specificity, y = sensitivity, col = model)) +\n                geom_path(lwd = 1.5, alpha = 0.8) +\n                geom_abline(lty = 3) +\n                coord_equal() +\n                scale_color_viridis_d(option = \"plasma\", end = .6)\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-81-1.png){width=672}\n:::\n:::\n\n\nDe laatste fit.\n\nBouw het model opnieuw op en neem de beste hyperparameter waarde voor ons 'random forest model'. Definieer ook een nieuw argument: `importance = \"impurity\"`\n\nHet laatste model ziet er dan zo uit.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlast_rf_mod <-\n                rand_forest(mtry = 8, min_n = 7, trees = 1000) %>%\n                set_engine(\"ranger\", num.threads = cores, importance = \"impurity\") %>%\n                set_mode(\"classification\")\n        ## Laatste werkflow\n        last_rf_workflow <-\n                rf_workflow %>%\n                update_model(last_rf_mod)\n```\n:::\n\n\nDe laatste fit dan nu.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n set.seed(345)\n        last_rf_fit <-\n                last_rf_workflow %>%\n                last_fit(splits)\n```\n:::\n\n\nEvalueer het model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlast_rf_fit %>%\n                collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric  .estimator .estimate .config             \n  <chr>    <chr>          <dbl> <chr>               \n1 accuracy binary         0.946 Preprocessor1_Model1\n2 roc_auc  binary         0.923 Preprocessor1_Model1\n```\n:::\n\n```{.r .cell-code}\n        ## 6.5 review variable importance ----\n        last_rf_fit %>%\n                pluck(\".workflow\", 1) %>%\n                pull_workflow_fit() %>%\n                vip(num_features = 20)\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-84-1.png){width=672}\n:::\n:::\n\n\nLaatste roc, zelfde voor de validatie set. Goede voorspeller op de nieuwe data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlast_rf_fit %>%\n                collect_predictions() %>%\n                roc_curve(children, .pred_children) %>%\n                autoplot()\n```\n\n::: {.cell-output-display}\n![](TutorialALL_files/figure-html/unnamed-chunk-85-1.png){width=672}\n:::\n:::\n\n\n# Literatuur\n\n-   https://www.tidymodels.org/, met name https://www.tidymodels.org/start/.\\\n-   Kuhn, M. & Silge, J. (2022). *Tidy Modeling with R. A Framework for Modeling in the Tidyverse*. Boston: Sebastopol (CA): O'Reilly. zie: https://www.tmwr.org\n",
    "supporting": [
      "TutorialALL_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}